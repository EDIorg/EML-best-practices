[["index.html", "Data Package Best Practices Data Package Best Practices", " Data Package Best Practices Environmental Data Initiative 2022-03-04 Data Package Best Practices Overview This website contains current \"Best Practice\" recommendations for ecological and environmental science data packages. These recommendations are directed towards the following goals: Minimize heterogeneity of EML-described data packages to simplify development and re-use of software Maximize interoperability to facilitate data synthesis Provide guidance and clarification on the use of Ecological Metadata Language (EML) design a data package prepare a data product for synthesis To participate in the “Best Practices for Data Packages” project, see “About this site.” EML Metadata Concepts The recommendations for EML metadata apply to all data packages. This section subsumes V3 of the static PDF document “Best Practices for Dataset Metadata in Ecological Metadata Language (EML),” last updated in 2017. The entire most recent (versioned, citable) release will be made available as a PDF. Best Practices for Dataset Metadata in Ecological Metadata Language (EML) Data Package Design Considerations for a well designed data package including special cases based on data type, format, or acquisition method. Examples are images, documents, raw data stored in other repositories. Recommendations for data package design Data Products for Synthesis Research Recommendations for community developed data products. The data packages are derived from raw data and reformatted to meet certain data harmonization standards. Many of these data products have extensive related code bases, which recommendations can take into account and link to. Recommendations for data products from specific scientific domains "],["about-this-site.html", "About This Site", " About This Site General Git repository: https://github.com/EDIorg/data-package-best-practices All pages can be edited in markdown Served as gh-pages (from the docs dir) Contributions can be from many (via fork and pull request), moderated by a committee Section organization Index section A very few pages of introductory material (including this page) and a navigation menu Based on a fork of http://bruth.github.io/jekyll-docs-template/ Changes (after pushed to github) are public immediately Best Practice sections Composed of multiple sections, each composed of multiple pages and moderated by the appropriate committee Each section is generated as a separate “book,” with R-bookdown (a wrapper for pandoc, in R) Edited pages do not become public until the book is rebuilt We use bookdown here to support these objectives: Pages can remain in development until they are explicitly posted, e.g., after moderation and build PDFs can be generated as needed for citable versions e.g., “Best Practices for EML metadata, V 4,” anticipated in early 2020 Instructions Index section How to add new pages to the Index section Fork the repository Add a file to the /docs/_posts directory. Since the template is blog-based, we follow the convention YYYY-MM-DD-name-of-post.md Option 1: do it manually and include the necessary front matter. Take a look at the source for this page to see how it works Option 2: use the script to generate an empty file with front matter. The advantage of using the script is that it automatically creates a soft link in the _pages directory without the date, which makes editing easier. If you want to control order, add the order to the front matter. Example: bash-3.2$ ./bin/jekyll-page \"About This Website\" about How to Link Files are in markdown, which means you can include HTML. Use site tokens whenever possible. See Markdown Basics for more info. link to a file: &lt;a href=\"{{ site.baseurl }}/files/966.pdf\"&gt;link to 966.pdf&lt;/a&gt; link to an image: end of img. Menu navigation is controlled by categories, labeled in the _config.yml and assigned in each page’s front matter. We are currently using only two navigation sections: - tut, for BP-templates, how-tos for markdown, - about, general info on how this website is generated (this page). See the _config.yml for the navigation sections (and other site-wide material, like tokens) BP sections: The major sections of this site are written in Markdown, and transformed to HTML with the R bookdown package. Instructions for using bookdown can be found with other information for contributors, under “Using Bookdown” Remember: each BP book is independent. "],["eml-best-practices.html", "EML Best Practices", " EML Best Practices This document contains current ‘Best Practice’ recommendations for EML content for metadata related to ecological and environmental data. It is intended to augment the EML schema documentation (Jones et al. 2019) for a less-technical audience. This is one component of several resources available to EML preparers. These recommendations are directed towards the following goals: Provide guidance and clarification in the implementation of EML for datasets Minimize heterogeneity of EML documents to simplify development and re-use of software built to ingest it Maximize interoperability of EML documents to facilitate data synthesis References "],["introduction.html", "Introduction", " Introduction EML Best Practice recommendations have evolved over time. The most active contributors have been members of the LTER Information Managers Committee in multiple working groups and workshops. EML has been widely used for several years with multiple applications written against it, and the community has had the opportunity to observe the consequences of many content patterns. As much as possible, recommendations have been aligned with those experiences, as well as with the capability of data contributors. Timeline and Previous Revisions 2017 Best Practices for Dataset Metadata in EML v3 (this document) 2016 EDI inception, see http://environmentaldatainitiative.org 2011 EML Best Practices for LTER sites v2 2008 EML 2.1 release 2004 EML Best Practices for LTER sites 2003 LTER adopts EML as network exchange standard Contributors, including LTER EML Best Practices Working Groups and workshops in 2003, 2004, 2010 (alphabetical order): Dan Bahauddin Barbara Benson Emery Boose James Brunt Duane Costa Corinna Gries Don Henshaw Margaret O’Brien Ken Ramsey Inigo San Gil Mark Servilla Wade Sheldon Philip Tarrant Theresa Valentine John Vande Castle, Kristin Vanderbilt Jonathan Walsh Yang Xia "],["conventions-and-definitions.html", "Conventions and Definitions", " Conventions and Definitions Audience This document is intended for data managers. It assumes that readers are familiar with the basic structure of an XML document, and the ability to edit in an XML editor like OxygenXML or XMLSpy. the process for contributing data to a repository. If you reached this document from a repository’s help-page, contact them for more information. Fonts and typeface Numbered examples of EML nodes are in fixed-width font: &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; XML element and attribute names, XPath and references to element names in text are in bold face. Single element names are surrounded by angle brackets, as they appear in XML. &lt;dataTable&gt; /eml:eml/@packageId Some recommendations have special context, e.g., an XML element or attribute may be requested by a community (e.g., LTER), or required by the EDI repository (but not by other repositories). Context notes: Recommendations for EML usage in a specific context are called “context notes,” and are placed in separate paragraphs, in italic. Definitions EML preparer the person responsible for “building” the EML metadata record. Generally, this is a data manager working with a project or physical site that produces data. Contributor the research project contributing the data package, e.g., an LTER or OBFS site, or a Macrosystems project. Generally, the “EML preparer” works with or for the “Contributor.” Data package the EML metadata together with its entity or entities. This is generally the unit housed in repositories. We use this term to avoid confusion with the EML element “dataset.” Other EML Resources Some sections refer to further information or tools. These can be found on the EDI website, under “Resources and How To…,” at https://environmentaldatarepository.org "],["general-recommendations.html", "General Recommendations", " General Recommendations Following are general best practices for handling EML dataset metadata: Metadata Distribution Do not publicly distribute EML documents containing elements with incorrect information, e.g., as a workaround for missing metadata or to meet validation requirements. Pre-publication drafts, or EML produced for demonstration or testing purposes should be clearly identified as such and not contributed to public archives, because these are passed on to large-scale clearinghouses. For previews of drafts or handling test and demonstration data packages, consult your repository to learn about options. Data Package Identifiers Metadata and data set versioning are controlled by the contributor, and so identifiers are tied to local systems. Many repository systems that accept EML-described data support principles of immutable metadata and data entity versioning. EML has elements to contain package identifiers, although these may also be assigned externally. It is the responsibility of the submitters to understand the practices of their intended repository when using identifiers. High-priority Elements To support locating data by time, geographic location, and taxonomically, metadata should provide as much information as possible for the data package, in the three &lt;coverage&gt;; elements: &lt;temporalCoverage&gt;; (when), &lt;geographicCoverage&gt;; (where) and &lt;taxonomicCoverage&gt; (what). For a potential user to evaluate the relevance and usability of the data package for their research study or synthesis projects, metadata should include detailed descriptions in the &lt;project&gt;, &lt;methods&gt;, &lt;protocols&gt;, and &lt;intellectualRights&gt; elements. "],["Root_element.html", "The root element: &lt;eml:eml&gt;", " The root element: &lt;eml:eml&gt; This element is the root element in all EML documents. The XPath notation is: /eml:eml The root element holds two important parts, both of which are optional, but recommended. @schemaLocation (XML attribute) This attribute is this location (XPath): /eml:eml/@schemaLocation The schemaLocation attribute tells a processor the name of the schema to which the EML document belongs and where to find it. Most repositories check schema compliance when data packages are deposited, but it is highly recommended that data managers know how and where to specify the schema that their metadata document should adhere to. This way, they can validate their own work in progress, e.g., through an XML editor like OxygenXML. @packageId (XML attribute) This attribute is found at this location (XPath): /eml:eml/@packageId As outlined elsewhere, EML preparers should manage unique identifiers and versioning at the local level (see @system discussion below). The packageId attribute can be used to contain the same identifier as is used by the repository. Context Note: The packageID attribute is required in all EML documents submitted to the EDI repository. It is entered into the repository software, and theformat is standardized to three parts: scope, package-number, revision. The scope should be “edi” unless another scope is justified by prior arrangement. See Example 1. Example 1: attributes packageId, id, system, and scope &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;eml:eml xmlns:ds=&quot;eml://ecoinformatics.org/dataset-2.1.0&quot; xmlns:xs=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:eml=&quot;eml://ecoinformatics.org/eml-2.1.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:stmml=&quot;http://www.xml-cml.org/schema/stmml&quot; xsi:schemaLocation=&quot;eml://ecoinformatics.org/eml-2.1.0 https://nis.lternet.edu/eml-2.1.0/eml.xsd&quot; packageId=&quot;knb-lter-fls.21.3&quot; system=&quot;FLS&quot; scope=&quot;system&quot;&gt; "],["top-level-elements.html", "Top Level Elements", " Top Level Elements An EML dataset is composed of up to three elements under the root element (&lt;eml:eml&gt;): &lt;access&gt; More information: access &lt;dataset&gt; More information: dataset &lt;additionalMetadata&gt;More information: additionalMetadata "],["title-dataset.html", "title (dataset)", " title (dataset) The dataset title element is found at this location (XPath): /eml:eml/ dataset/title /eml:eml/method/methodStep/protocol/title /eml:eml/project/title The dataset &lt;title&gt; should be descriptive and should mention the data collected, geographic context, research site, and time frame (what, where, and when). Example 3: dataset, alternateIdentifier, shortName, title &lt;dataset id=&quot;FLS-1&quot; system=&quot;FLS&quot; scope = &quot;system&quot;&gt; &lt;alternateIdentifier&gt;FLS-1&lt;/alternateIdentifier&gt; &lt;shortName&gt;Arthropods&lt;/shortName&gt; &lt;title&gt;Long-term Ground Arthropod Monitoring Dataset at Ficity, USA from 1998 to 2003&lt;/title&gt; "],["people-and-organizations-parties.html", "People and Organizations (Parties)", " People and Organizations (Parties) People and organizations are all described using a “ResponsibleParty” group of elements, which is found at these locations (XPath): /eml:eml/dataset/creator /eml:eml/dataset/contact /eml:eml/dataset/metadataProvider /eml:eml/dataset/associatedParty /eml:eml/dataset/publisher /eml:eml/dataset/project/creator /eml:eml/dataset/method/methodStep/protocol/creator General recommendations: When using &lt;individualName&gt; elements anywhere within an EML document, names should be constructed with English alphabetization in mind. Many sites have found that maintaining full contact information for every creator is impractical, however a few important contact information should be kept up to date (see below). If a name includes a suffix, it should be included in the &lt;surName&gt; element after the last name. It is recommended to include complete contact information for a permanent role that is independent of the person holding that position. For example, for an information manager, site contact, pay careful attention to phone number and use an e-mail alias that can be passed on. (See below, under&lt;contact&gt;.) With the advent of general identifiers such as ORCIDs, the text in the &lt;address&gt;, &lt;phone&gt;, and &lt;onlineURL&gt; elements may become unnecessary for individuals and so is optional if and an individual’s ORCID is included. &lt;electronicMailAddress&gt; is recommended to simplify contacting responsible parties. See the &lt;userId&gt; field. ORCID identifiers are not yet available for organizations, so &lt;address&gt;, &lt;phone&gt;, and &lt;onlineURL&gt; elements should be included for them. In the examples, these elements are included for completeness. userId This element is found at this location (XPath): /eml:eml/dataset/creator/userId /eml:eml/dataset/contact/userId /eml:eml/dataset/metadataProvider/userId /eml:eml/dataset/associatedParty/userId /eml:eml/dataset/publisher/userId /eml:eml/dataset/project/creator/userId /eml:eml/dataset/method/methodStep/protocol/creator/userId The optional &lt;userId&gt; field holds identifiers for responsible parties from other systems. This element is repeatable so that multiple systems can be referenced. EML prepares should contact the system they plan to use to learn their preferences for inclusion in metadata. The examples here are for ORCID identifiers, and that organization has asked that its full URI be used as both the system attribute, and as the head of the identifier itself. Example 4: creator &lt;creator id=&quot;org-1&quot; system=&quot;FLS&quot; scope=&quot;system&quot;&gt; &lt;organizationName&gt;Fictitious LTER Site&lt;/organizationName&gt; &lt;address&gt; &lt;deliveryPoint&gt;Department for Ecology&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;Fictitious State University&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;PO Box 111111&lt;/deliveryPoint&gt; &lt;city&gt;Ficity&lt;/city&gt; &lt;administrativeArea&gt;FI&lt;/administrativeArea&gt; &lt;postalCode&gt;11111-1111&lt;/postalCode&gt; &lt;/address&gt; &lt;phone phonetype=&quot;voice&quot;&gt;(999) 999-9999&lt;/phone&gt; &lt;electronicMailAddress&gt;fsu.contact@fi.univ.edu&lt;/electronicMailAddress&gt; &lt;onlineUrl&gt;http://www.fsu.edu/&lt;/onlineUrl&gt; &lt;userId system=&quot;https://orcid.org&quot;&gt; https://orcid.org/0000-0000-0000-0000 &lt;/userId&gt; &lt;/creator&gt; &lt;creator id=&quot;pos-1&quot; system=&quot;FLS&quot; scope=&quot;system&quot;&gt; &lt;positionName&gt;FLS Lead PI&lt;/positionName&gt; &lt;address&gt; &lt;deliveryPoint&gt;Department for Ecology&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;Fictitious State University&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;PO Box 111111&lt;/deliveryPoint&gt; &lt;city&gt;Ficity&lt;/city&gt; &lt;administrativeArea&gt;FI&lt;/administrativeArea&gt; &lt;postalCode&gt;11111-1111&lt;/postalCode&gt; &lt;/address&gt; &lt;phone phonetype=&quot;voice&quot;&gt;(999) 999-9999&lt;/phone&gt; &lt;electronicMailAddress&gt;fsu.leadPI@fi.univ.edu&lt;/electronicMailAddress&gt; &lt;onlineUrl&gt;http://www.fsu.edu/&lt;/onlineUrl&gt; &lt;userId system=&quot;https://orcid.org&quot;&gt; https://orcid.org/0000-0000-0000-0000 &lt;/userId&gt; &lt;/creator&gt; &lt;creator id=&quot;pers-1&quot; system=&quot;FLS&quot; scope=&quot;system&quot;&gt; &lt;individualName&gt; &lt;salutation&gt;Dr.&lt;/salutation&gt; &lt;givenName&gt;Joe&lt;/givenName&gt; &lt;givenName&gt;T.&lt;/givenName&gt; &lt;surName&gt;Ecologist Jr.&lt;/surName&gt; &lt;/individualName&gt; &lt;organizationName&gt;FSL LTER&lt;/organizationName&gt; &lt;address&gt; &lt;deliveryPoint&gt;Department for Ecology&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;Fictitious State University&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;PO Box 111111&lt;/deliveryPoint&gt; &lt;city&gt;Ficity&lt;/city&gt; &lt;administrativeArea&gt;FI&lt;/administrativeArea&gt; &lt;postalCode&gt;11111-1111&lt;/postalCode&gt; &lt;/address&gt; &lt;phone phonetype=&quot;voice&quot;&gt;(999) 999-9999&lt;/phone&gt; &lt;electronicMailAddress&gt;jecologist@fi.univ.edu&lt;/electronicMailAddress&gt; &lt;onlineUrl&gt;http://www.fsu.edu/~jecologist&lt;/onlineUrl&gt; &lt;userId system=&quot;https://orcid.org&quot;&gt; https://orcid.org/0000-0000-0000-0000 &lt;/userId&gt; &lt;/creator&gt; creator This element is found at this location (XPath): /eml:eml/dataset/creator The &lt;creator&gt; is considered to be the author of the data package, i.e. the person(s) responsible for intellectual input into its creation. &lt;surName&gt; and &lt;givenName&gt; elements are used to build citations, so these should be completed fully for credit to be understandable. For long-term data, e.g., from an LTER Site, preparers should include the organization (using the &lt;organizationName&gt;) or current principal investigator (PI, using &lt;postitionName&gt;). It should be kept in mind that in the past, different approaches have led to confusion over how to best search for long-term data, and searchers frequently default to searches using PI’s last name. Therefore it is a reasonable practice to include more creators rather than fewer, even if it blurs the credit for long-term data. metadataProvider This element is found at this location (XPath): /eml:eml/dataset/metadataProvider The &lt;metadataProvider&gt; element lists the person or organization responsible for producing or providing the metadata content. For primary data sets generated by LTER sites, the LTER site should typically be listed under &lt;metadataProvider&gt; using the &lt;organizationName&gt; element. For acquired data sets, where the &lt;creator&gt; or &lt;associatedParty&gt; are not the same people who produced the metadata content, the actual metadata content provider should be listed instead (see Example below). Example 5: metadataProvider &lt;metadataProvider&gt; &lt;organizationName&gt;Fictitious LTER Site&lt;/organizationName&gt; &lt;address&gt; &lt;deliveryPoint&gt;Department of Ecology&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;Fictitious State University&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;PO Box 111111&lt;/deliveryPoint&gt; &lt;city&gt;Ficity&lt;/city&gt; &lt;administrativeArea&gt;FI&lt;/administrativeArea&gt; &lt;postalCode&gt;11111-1111&lt;/postalCode&gt; &lt;/address&gt; &lt;phone phonetype=&quot;voice&quot;&gt;(999) 999-9999&lt;/phone&gt; &lt;electronicMailAddress&gt;fsu@fi.univ.edu&lt;/electronicMailAddress&gt; &lt;onlineUrl&gt;http://www.fsu.edu/&lt;/onlineUrl&gt; &lt;userId system=&quot;https://orcid.org&quot;&gt; https://orcid.org/0000-0000-0000-0000 &lt;/userId&gt; &lt;/metadataProvider&gt; associatedParty This element is found at this location (XPath): /eml:eml/dataset/associatedParty List other people who were involved with the data in some way (field technicians, students assistants, etc.) as &lt;associatedParty&gt;. All &lt;associatedParty&gt; trees require a &lt;role&gt; element. The parent university, institution, or agency could also be listed as an &lt;associatedParty&gt; using &lt;role&gt; of “owner” when appropriate. Example 6: associatedParty &lt;associatedParty id=&quot;12010&quot; system=&quot;FLS&quot; scope=&quot;system&quot;&gt; &lt;individualName&gt; &lt;givenName&gt;Ima&lt;/givenName&gt; &lt;surName&gt;Testuser&lt;/surName&gt; &lt;/individualName&gt; &lt;organizationName&gt;FSL LTER&lt;/organizationName&gt; &lt;address&gt; &lt;deliveryPoint&gt;Department for Ecology&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;Fictitious State University&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;PO Box 111111&lt;/deliveryPoint&gt; &lt;city&gt;Ficity&lt;/city&gt; &lt;administrativeArea&gt;FI&lt;/administrativeArea&gt; &lt;postalCode&gt;11111-1111&lt;/postalCode&gt; &lt;/address&gt; &lt;phone phonetype=&quot;voice&quot;&gt;(999) 999-9999&lt;/phone&gt; &lt;electronicMailAddress&gt;itestuser@lternet.edu&lt;/electronicMailAddress&gt; &lt;onlineUrl&gt;http://search.lternet.edu/directory_view.php?personid=12010&amp;amp;query=itestuser&lt;/onlineUrl&gt; &lt;userId system=&quot;https://orcid.org&quot;&gt; https://orcid.org/0000-0000-0000-0000 &lt;/userId&gt; &lt;role&gt;Technician&lt;/role&gt; &lt;/associatedParty&gt; contact This element is found at this location (XPath): /eml:eml/dataset/contact A &lt;contact&gt; element is required in all EML metadata records. Full contact information should be included for the position of data manager or other designated contact, and should be kept current and independent of personnel changes. If several contacts are listed (e.g. both a data and site manager) all should be kept current. Technicians who performed the work belong under &lt;associatedParty&gt; rather than &lt;contact&gt;. Complete the &lt;address&gt;, &lt;phone&gt;, &lt;electronicMailAddress&gt;, and &lt;onlineURL&gt; elements for the &lt;contact&gt; element. Example 7: contact &lt;contact&gt; &lt;positionName id=&quot;pos-4&quot;&gt;Information Manager&lt;/positionName&gt; &lt;address&gt; &lt;deliveryPoint&gt;Department for Ecology&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;Fictitious State University&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;PO Box 111111&lt;/deliveryPoint&gt; &lt;city&gt;Ficity&lt;/city&gt; &lt;administrativeArea&gt;FI&lt;/administrativeArea&gt; &lt;postalCode&gt;11111-1111&lt;/postalCode&gt; &lt;/address&gt; &lt;phone phonetype=&quot;voice&quot;&gt;(999) 999-9999&lt;/phone&gt; &lt;electronicMailAddress&gt;fsu.data@fi.univ.edu&lt;/electronicMailAddress&gt; &lt;onlineUrl&gt;http://www.fsu.edu/&lt;/onlineUrl&gt; &lt;userId system=&quot;https://orcid.org&quot;&gt; https://orcid.org/0000-0000-0000-0000 &lt;/userId&gt; &lt;/contact&gt; publisher This element is found at this location (XPath): /eml:eml/dataset/publisher The organization producing the EML metadata (e.g., an LTER site or field station) should be placed in the &lt;publisher&gt; element. Spell out the organization’s name (&lt;organizationName&gt;). Complete the &lt;address&gt;, &lt;phone&gt;, &lt;electronicMailAddress&gt;, and &lt;onlineURL&gt; elements for each publisher element. Some citation displays may use this element, although typically, the repository becomes the publisher in citations. Example 8: publisher &lt;publisher&gt; &lt;organizationName&gt;Fictitious LTER site&lt;/organizationName&gt; &lt;/publisher&gt; "],["pubdate.html", "pubDate", " pubDate This element is found at this location (XPath): /eml:eml/dataset/pubDate The year of public release of data online should be listed as the &lt;pubDate&gt; element. Because this element may be used in constructing citations, the pubDate also should reflect the ‘recentness’ of a package, with pubDate updated along with significant revision or data additions (e.g., corrected data, or additions to an ongoing time series). There is an argument for pubDate referring to original date of release, but this is probably only useful for static data packages, or if the only metadata changes are to enhance discovery. "],["abstract.html", "abstract", " abstract This element is found at these locations (XPath): /eml:eml/dataset/abstract /eml:eml/dataset/project/abstract For a dataset, the abstract element can appear at the resource level or the project level. The &lt;abstract&gt; element will be used for full-text searches, and it should be rich with descriptive text. In particular, descriptions should include information that does not fit into structured metadata, and focus on the “what,” “when,” and “where” information, general taxonomic information, as well as whether the dataset is ongoing or completed. Some general methods description is appropriate, and broad classes of measured parameters should also be included. For a large number of parameters, use categories instead of listing all parameters (e.g. use the term “nutrients” instead of nitrate, phosphate, calcium, etc.), in combination with the parameters that seem most relevant for searches. "],["keywordset-and-keyword.html", "keywordSet and keyword", " keywordSet and keyword This element is found at these locations (XPath): /eml:eml/dataset/keywordSet /eml:eml/dataset/project/keywordSet It is recommended that meaningful sets of keywords each be contained within &lt;keywordSet&gt; tag. Use one &lt;keywordSet&gt; for a group of terms identifying the contributing organization(s), e.g., the LTER or OBFS site, LTREB or Macrosystems project , which is especially if data are co-funded or funding is leveraged. Meaningful geographic place names also are appropriate (e.g. state, city, county). If groups of keywords are from a specific vocabulary, its name belongs the optional tag &lt;keywordThesaurus&gt;. Context: Communities sometimes have specific requests for keywords to assist in searches. E.g, the LTER requests that keywords should include a LTER core research area(s), the network acronym (LTER, ILTER, etc.), three-letter site acronym and site name. In addition to specific keywords, relevant conceptual keywords should also be included, e.g., from the LTER Controlled Vocabulary. Example 9: pubDate, abstract,keywordSet, keyword &lt;pubDate&gt;2014&lt;/pubDate&gt; &lt;abstract&gt; &lt;para&gt;Ground arthropods communities are monitored in different habitats in a rapidly changing environment. The arthropods are collected in traps four times a year in ten locations and determined as far as possible to family, genus or species.&lt;/para&gt; &lt;/abstract&gt; &lt;keywordSet&gt; &lt;keyword keywordType=&quot;place&quot;&gt;City&lt;/keyword&gt; &lt;keyword keywordType=&quot;place&quot;&gt;State&lt;/keyword&gt; &lt;keyword keywordType=&quot;place&quot;&gt;Region&lt;/keyword&gt; &lt;keyword keywordType=&quot;place&quot;&gt;County&lt;/keyword&gt; &lt;keyword keywordType=&quot;theme&quot;&gt;FLS&lt;/keyword&gt; &lt;keyword keywordType=&quot;theme&quot;&gt;Fictitious LTER Site&lt;/keyword&gt; &lt;keyword keywordType=&quot;theme&quot;&gt;LTER&lt;/keyword&gt; &lt;keyword keywordType=&quot;theme&quot;&gt;Arthropods&lt;/keyword&gt; &lt;keyword keywordType=&quot;theme&quot;&gt;Richness&lt;/keyword&gt; &lt;keywordThesaurus&gt;FLS site thesaurus&lt;/keywordThesaurus&gt; &lt;/keywordSet&gt; &lt;keywordSet&gt; &lt;keyword keywordType=&quot;theme&quot;&gt;ecology&lt;/keyword&gt; &lt;keyword keywordType=&quot;theme&quot;&gt;biodiversity&lt;/keyword&gt; &lt;keyword keywordType=&quot;theme&quot;&gt;population dynamics&lt;/keyword&gt; &lt;keyword keywordType=&quot;theme&quot;&gt;terrestrial&lt;/keyword&gt; &lt;keyword keywordType=&quot;theme&quot;&gt;arthropods&lt;/keyword&gt; &lt;keyword keywordType=&quot;theme&quot;&gt;pitfall trap&lt;/keyword&gt; &lt;keyword keywordType=&quot;theme&quot;&gt;monitoring&lt;/keyword&gt; &lt;keyword keywordType=&quot;theme&quot;&gt;abundance&lt;/keyword&gt; &lt;keywordThesaurus&gt;LTER controlled vocabulary&lt;/keywordThesaurus&gt; &lt;/keywordSet&gt; &lt;keywordSet&gt; &lt;keyword keywordType=&quot;theme&quot;&gt;populations&lt;/keyword&gt; &lt;keywordThesaurus&gt;LTER core research areas&lt;/keywordThesaurus&gt; &lt;/keywordSet&gt; "],["intellectualrights.html", "intellectualRights", " intellectualRights This element is found at this location (XPath): /eml:eml/dataset/intellectualRights &lt;intellectualRights&gt; are controlled at the source, however it is recommended that data be released with as few restrictions as possible. Each data package should contain a data access policy, plus a description of any deviation from the general policy specific for this particular package (e.g. restricted-access packages). The timeframe for release should be included as well. Context: If no &lt;intellectualRights&gt; element is included EDI will insert text that releases data under “CC-0” (shown in example). The LTER Network-wide default policy is “CC-BY.” Please consult those organizations for more information and more details. Example 10: intellectualRights &lt;intellectualRights&gt; &lt;section&gt; &lt;title&gt;Data Policy&lt;/title&gt; &lt;para&gt;This data package is released to the &quot;public domain&quot; under Creative Commons CC0 1.0 &quot;No Rights Reserved&quot; (see: https://creativecommons.org/publicdomain/zero/1.0/). It is considered professional etiquette to provide attribution of the original work if this data package is shared in whole or by individual components. A generic citation is provided for this data package on the website https://portal.edirepository.org (herein &quot;website&quot;) in the summary metadata page. Communication (and collaboration) with the creators of this data package is recommended to prevent duplicate research or publication. This data package (and its components) is made available &quot;as is&quot; and with no warranty of accuracy or fitness for use. The creators of this data package and the website shall not be liable for any damages resulting from misinterpretation or misuse of the data package or its components. Periodic updates of this data package may be available from the website. Thank you.&lt;/para&gt; &lt;/section&gt; &lt;/intellectualRights&gt; "],["distribution.html", "distribution", " distribution This element is found at these locations (XPath): /eml:eml/dataset/distribution /eml:eml/dataset/[entity]/physical/distribution The &lt;distribution&gt; element can appear at both the dataset and entity levels. Dataset level At the dataset level, the &lt;distribution&gt; element should be used for information only, because it applies to the entire package, not only to one entity. Context: The EDI repository will ignore a &lt;distribution&gt; element at the dataset level. Example 11a: distribution at the dataset level &lt;distribution&gt; &lt;online&gt; &lt;onlineDescription&gt;f1s-1 Data Web Page&lt;/onlineDescription&gt; &lt;url function=&quot;information&quot;&gt; http://www.fsu.edu/lter/data/fls-1.htm &lt;/url&gt; &lt;/online&gt; &lt;/distribution&gt; Entity level The entity-level &lt;distribution&gt; element contains information on how that specific data entity (e.g., data table) can be accessed. The &lt;distribution&gt; element has one of three children for describing the location of the resource: &lt;online&gt;, &lt;offline&gt;, and &lt;inline&gt;. Offline Data: Use the &lt;offline&gt; element to describe restricted access data or data that is not available online. The minimum that should be included is the &lt;mediumName&gt; tag, if using the &lt;offline&gt; element. Inline Data: The &lt;inline&gt; element contains data that is stored directly within the EML document. Data included as text or string will be parsed. If data are not to be parsed, encode them as “CDATA sections,” by surrounding them with “&lt;![CDATA[” and “]]&gt;” tags. Online Data: The &lt;online&gt; element has two sub elements, &lt;url&gt;, and &lt;onlineDescription&gt; (optional). &lt;url&gt; tags may have an optional attribute named function, which may be set to either “download” or “information.” If the “function” attribute is omitted, then “download” is implied. @function=“download”: accessing the URL directly returns the data stream @function=“information”: URL leads to a data catalog, intended-use page, or other page that provides information about downloading the object but does not directly return the data stream, then the “function” attribute should be set to “information.” Context: for am EML data package to be accepted into the EDI repository, it must include at least one URL; at the entity level (e.g., a dataTable at /eml:eml/dataset/dataTable/physical/distribution/url). The URL must include the function attribute with the value “download” (or empty, i.e., defaults to “download”). Context: The EDI repository system has alternatives for uploading data entities if you do not have a server which can deliver entities via a URL (http). Contact EDI for more information on these options. When used at the entity level, an alternative tag is available to &lt;url&gt;, called &lt;connection&gt;. This element is discussed under data entities, below. As of EML 2.1, there is also an optional &lt;access&gt; element in a &lt;distribution&gt; tree at the data entity level (/eml:eml/dataset/[entity]/physical/distribution/access). This element is intended specifically for controlling access to the data entity itself. For more information on the &lt;access&gt; tree, see above, under the general access discussion. Example 11b: distribution at the data entity level &lt;dataTable&gt; &lt;physical&gt; ... &lt;distribution&gt; &lt;online&gt; &lt;onlineDescription&gt;f1s-1 Data Web Page&lt;/onlineDescription&gt; &lt;url function=&quot;download&quot;&gt; http://www.fsu.edu/lter/data/fls-1.csv &lt;/url&gt; &lt;/online&gt; &lt;/distribution&gt; &lt;/physical&gt; &lt;/dataTable&gt; "],["coverage.html", "coverage", " coverage This element is found at these locations (XPath): /eml:eml/dataset/coverage /eml:eml/dataset/methods/sampling/studyExtent/coverage /eml:eml/dataset/methods/sampling/spatialSamplingUnits/coverage /eml:eml/dataset/[entity]/coverage /eml:eml/dataset/[entity]/methods/sampling/studyExtent/coverage /eml:eml/dataset/[entity]/methods/sampling/spatialSamplingUnits/coverage /eml:eml/dataset/[entity]/attributeList/attribute/coverage /eml:eml/dataset/[entity]/attributeList/attribute/methods/sampling/studyExtent/coverage /eml:eml/dataset/[entity]/attributeList/attribute/methods/sampling/spatialSamplingUnits/coverage /eml:eml/dataset/project/studyAreaDescription/coverage The &lt;coverage&gt; element can appear at the dataset, methods, entity and attribute levels, and contains three elements for describing the coverage in terms of space, taxonomy, and time, &lt;geographicCoverage&gt;, &lt;taxanomicCoverage&gt;, and &lt;temporalCoverage&gt;. Populating these elements as recommended enables advanced searches and understanding. Because they appear at many XPaths, there are many options for how coverage elements can be used. geographicCoverage General Information: The &lt;geographicCoverage&gt; element describes locations of research sites and areas related to the data, and is intended for general placement of points on a map. It is recommended to use the element at different levels for different types of information. The cardinality of the &lt;geographicCoverage&gt; element is one-to-many. The miminum requirement under &lt;geographicCoverage&gt; is two elements, a &lt;geographicDescription&gt; and &lt;boundingCoordinates&gt; with a bounding box containing N, S, E, W limits. At the dataset level (eml:eml/dataset/coverage) one &lt;geographicCoverage&gt; element should be included, whose &lt;boundingCoordinates&gt; describe the extent of the data. As a default, this could be the nominal boundaries of a sampling area. A more accurate extent (recommended) would be the maximum extent of the data, for each of east, west, north and south. Additional &lt;geographicCoverage&gt; elements should be included if there are significant distances between study sites and grouping them in one bounding box would be misleading or confusing. For example, a cross-site study should have bounding boxes for each site. Example 12: geographicCoverage at the dataset level &lt;coverage&gt; &lt;geographicCoverage&gt; &lt;geographicDescription&gt; Ficity, FI metropolitan area, USA &lt;/geographicDescription&gt; &lt;boundingCoordinates&gt; &lt;westBoundingCoordinate&gt;-112.373614&lt;/westBoundingCoordinate&gt; &lt;eastBoundingCoordinate&gt;-111.612936&lt;/eastBoundingCoordinate&gt; &lt;northBoundingCoordinate&gt;33.708829&lt;/northBoundingCoordinate&gt; &lt;southBoundingCoordinate&gt;33.298975&lt;/southBoundingCoordinate&gt; &lt;boundingAltitudes&gt; &lt;altitudeMinimum&gt;300&lt;/altitudeMinimum&gt; &lt;altitudeMaximum&gt;600&lt;/altitudeMaximum&gt; &lt;altitudeUnits&gt;meter&lt;/altitudeUnits&gt; &lt;/boundingAltitudes&gt; &lt;/boundingCoordinates&gt; &lt;/geographicCoverage&gt; &lt;/coverage&gt; If sampling took place in discrete point location, those sites should also appear with or without a bounding box. Individual sampling sites may also be be entered under &lt;spatialSamplingUnits&gt;, each site in a separate coverage element (see below). Example 13: geographicCoverage under spatialSamplingUnits &lt;spatialSamplingUnits&gt; &lt;coverage&gt; &lt;geographicDescription&gt;sitenumber 1&lt;/geographicDescription&gt; &lt;boundingCoordinates&gt; &lt;westBoundingCoordinate&gt;-112.2&lt;/westBoundingCoordinate&gt; &lt;eastBoundingCoordinate&gt;-112.2&lt;/eastBoundingCoordinate&gt; &lt;northBoundingCoordinate&gt;33.5&lt;/northBoundingCoordinate&gt; &lt;southBoundingCoordinate&gt;33.5&lt;/southBoundingCoordinate&gt; &lt;/boundingCoordinates&gt; &lt;/coverage&gt; &lt;coverage&gt; &lt;geographicDescription&gt;sitenumber 2&lt;/geographicDescription&gt; &lt;boundingCoordinates&gt; &lt;westBoundingCoordinate&gt;-111.7&lt;/westBoundingCoordinate&gt; &lt;eastBoundingCoordinate&gt;-111.7&lt;/eastBoundingCoordinate&gt; &lt;northBoundingCoordinate&gt;33.6&lt;/northBoundingCoordinate&gt; &lt;southBoundingCoordinate&gt;33.6&lt;/southBoundingCoordinate&gt; &lt;/boundingCoordinates&gt; &lt;/coverage&gt; &lt;coverage&gt; &lt;geographicDescription&gt;sitenumber 3&lt;/geographicDescription&gt; &lt;boundingCoordinates&gt; &lt;westBoundingCoordinate&gt;-112.1&lt;/westBoundingCoordinate&gt; &lt;eastBoundingCoordinate&gt;-112.1&lt;/eastBoundingCoordinate&gt; &lt;northBoundingCoordinate&gt;33.7&lt;/northBoundingCoordinate&gt; &lt;southBoundingCoordinate&gt;33.7&lt;/southBoundingCoordinate&gt; &lt;/boundingCoordinates&gt; &lt;/coverage&gt; &lt;/spatialSamplingUnits&gt; Latitudes and longitudes should be in the same datum, commonly used (i.e., all values in WGS84 or NAD83) and expressed to at least six decimal places (the EML2.1 schema enforces decimal content). International convention dictates that longitudes east of the prime meridian and latitudes north of the equator be prefixed with a plus sign (+), or by the absence of a minus sign (-), and that west longitudes and south latitudes be prefixed with minus sign (-). See Example below, and the EML specification for more information and other examples. &lt;geographicDescription&gt; The description is a string. It should be comprehensive so that searches can be run against it, and include the country, state, county or province, city, general topography, landmarks, rivers and other relevant information. The method for determining &lt;boundingCoordinates&gt;, &lt;boundingAltitudes&gt;, coordinates, datums, etc., should be included with the &lt;geographicDescription&gt;, since those elements do not encode this information. The &lt;datasetGPolygon&gt; element may be included when the required bounding box does not adequately describe the study location, for example, if an irregular polygon is necessary to describe the study area, or there is an area within the bounding box that is excluded. This element is optional, and has two subelements. &lt;datasetGPolygonOuterGRing&gt;: This is the outer part of the polygon shape that encompasses the broadest area of coverage. It can be created either by a gRing (list of points) or 4 or more &lt;gRingPoint&gt;s. Documentation for an FGDC G-Ring states that four points are required to define a polygon, and the first and last should be identical. However this is not enforceable in XML Schema, and so in EML a minimum of three &lt;gRingPoint&gt;s is required to define the polygon, and it can be assumed that a since a polygon is closed, the last point can be joined to the first. The &lt;datasetGPolygonExclusionGRing&gt; is the closed, nonintersecting boundary of a void area (or hole in an interior area). This could be the center of the doughnut shape created by the &lt;datasetGPolygon&gt;. It can be created either by a gRing (list of points) or one or more &lt;gRingPoint&gt;s. This is used if there is an internal polygon to be excluded from the outer polygon, e.g, a lake to be excluded from the broader geographic coverage. There are alternative methods for including location information with EML, especially when it is intended for use in an external application. GIS shape files, Keyhole Markup Language (KML or KMZ), or EML spatial modules can be included as data entities (see additional resources for different data file types at EDI). temporalCoverage The &lt;temporalCoverage&gt; element represents the period of time the data were collected, not the year the study was conducted if it uses retrospective or historical data. Most commonly, &lt;singleDate&gt; or &lt;rangeOfDates&gt; elements are used. Sometimes an &lt;alternativeTimeScale&gt; is more appropriate, such as the use of “years before present,” e.g., for long-term tree ring chronology dating back hundreds of years. Two formats are allowed, either a 4-digit year, or a date in ISO format: YYYY-MM-DD. In some cases, a package may be considered “ongoing,” i.e., data are planned to be added at intervals. It is not currently valid to leave an empty &lt;endDate&gt; tag in EML. Further, EML is intended to house “snapshots” of data which can be immutable (if the repository supports). So for a package which is planned to be ongoing, the best solution is to populate the &lt;endDate&gt; element with the end of the current data range and to update this metadata field along with data updates, so that the &lt;endDate&gt; tag reflects only the data that have already been included. It is better to state an end date that guarantees that data are present up to that date with more data possibly being available, than an end date in the future that includes a period of time for which no data are yet available. Use the &lt;maintanence&gt; tag (below) to describe the update frequency. The methods/sampling tree should be used to describe the ongoing nature of the data collection. Example 14: temporalCoverage &lt;temporalCoverage&gt; &lt;rangeOfDates&gt; &lt;beginDate&gt; &lt;calendarDate&gt;1998-11-12&lt;/calendarDate&gt; &lt;/beginDate&gt; &lt;endDate&gt; &lt;calendarDate&gt;2003-12-31&lt;/calendarDate&gt; &lt;/endDate&gt; &lt;/rangeOfDates&gt; &lt;/temporalCoverage&gt; taxonomicCoverage The &lt;taxonomicCoverage&gt; element should be used to document taxonomic information for all organisms relevant to the study. The lowest available level, preferably the species binomial and common name should always be included, but higher-level taxa should also be included to support broader taxonomic searches. Blocks of &lt;taxonomicClassification&gt; elements should be hierarchically nested within a single &lt;taxonomicCoverage&gt; element rather than repeated at the same level. The &lt;generalTaxonomicCoverage&gt; element could include a) descriptions of the general procedure of how the taxonomy was determined (keys used, etc.), b) general textual description of all flora/fauna in the study (scope), and c) denote how finely grained the taxonomy is – for example to “family” or “genus and species.” Note that it is allowable to combine elements in the hierarchy under like &lt;taxonRankName&gt; entries to create a taxonomic “tree” (not illustrated), but this practice may impede combining and re-using &lt;taxonomicClassification&gt; information from multiple documents so should be considered carefully. The optional taxonomicCoverage/taxonomicSystem trees may be used to detail the use of taxonomic identification resources and on the identification process. &lt;classificationSystem&gt; should be used to list authoritative taxonomic databases (such as ITIS, IPNI, NCBI, Index Fungorum, or USDA Plants) or classification systems used for taxonomic identification. Documentation and relevant literature regarding, used authoritative sources, including URL’s pointing to these sources, should be listed in &lt;classificationSystemCitation&gt;. Exceptions to, or deviation from, used authoritative sources should be explained in &lt;classificationSystemModification&gt;. Methods and protocols used for taxonomic classification should be detailed using the &lt;identifierName&gt; and &lt;taxonomicProcedures&gt; tags. Examples of methods that should be listed in &lt;taxonomicProcedures&gt; are details of specimen processing, keys, and chemical or genetic analyses. &lt;taxonomicCompleteness&gt; may be used to document the status, estimated importance, and reason for incomplete identifications. Example 15: taxonomicCoverage &lt;taxonomicCoverage&gt; &lt;taxonomicSystem&gt; &lt;classificationSystem&gt; &lt;classificationSystemCitation&gt; &lt;title&gt;Integrated Taxonomic Information System (ITIS)&lt;/title&gt; &lt;creator&gt; &lt;organizationName&gt; Integrated Taxonomic Information System &lt;/organizationName&gt; &lt;onlineUrl&gt;http://www.itis.gov/&lt;/onlineUrl&gt; &lt;/creator&gt; &lt;generic&gt; &lt;publisher&gt; &lt;organizationName&gt; Integrated Taxonomic Information System &lt;/organizationName&gt; &lt;onlineUrl&gt;http://www.itis.gov/&lt;/onlineUrl&gt; &lt;/publisher&gt; &lt;/generic&gt; &lt;/classificationSystemCitation&gt; &lt;/classificationSystem&gt; &lt;identifierName&gt; &lt;references&gt;pers-1&lt;/references&gt; &lt;/identifierName&gt; &lt;taxonomicProcedures&gt; All individuals where identified and stored in alcohol, except for one voucher specimen for each species which was tagged and pinned. &lt;/taxonomicProcedures&gt; &lt;/taxonomicSystem&gt; &lt;generalTaxonomicCoverage&gt; Orthopteran insects (grasshoppers) were identified to species &lt;/generalTaxonomicCoverage&gt; &lt;taxonomicClassification&gt; &lt;taxonRankName&gt;Kingdom&lt;/taxonRankName&gt; &lt;taxonRankValue&gt;Animalia&lt;/taxonRankValue&gt; &lt;taxonomicClassification&gt; &lt;taxonRankName&gt;Phylum&lt;/taxonRankName&gt; &lt;taxonRankValue&gt;Mollusca&lt;/taxonRankValue&gt; &lt;taxonomicClassification&gt; &lt;taxonRankName&gt;Class&lt;/taxonRankName&gt; &lt;taxonRankValue&gt;Gastropoda&lt;/taxonRankValue&gt; &lt;taxonomicClassification&gt; &lt;taxonRankName&gt;Order&lt;/taxonRankName&gt; &lt;taxonRankValue&gt;Basommatophora&lt;/taxonRankValue&gt; &lt;taxonomicClassification&gt; &lt;taxonRankName&gt;Genus&lt;/taxonRankName&gt; &lt;taxonRankValue&gt;Detracia&lt;/taxonRankValue&gt; &lt;taxonomicClassification&gt; &lt;taxonRankName&gt;Species&lt;/taxonRankName&gt; &lt;taxonRankValue&gt;Detracia floridana&lt;/taxonRankValue&gt; &lt;commonName&gt;Florida Melampus&lt;/commonName&gt; &lt;/taxonomicClassification&gt; &lt;/taxonomicClassification&gt; &lt;/taxonomicClassification&gt; &lt;/taxonomicClassification&gt; &lt;/taxonomicClassification&gt; &lt;/taxonomicClassification&gt; &lt;taxonomicClassification&gt; &lt;taxonRankName&gt;Kingdom&lt;/taxonRankName&gt; &lt;taxonRankValue&gt;Animalia&lt;/taxonRankValue&gt; &lt;taxonomicClassification&gt; &lt;taxonRankName&gt;Phylum&lt;/taxonRankName&gt; &lt;taxonRankValue&gt;Mollusca&lt;/taxonRankValue&gt; &lt;taxonomicClassification&gt; &lt;taxonRankName&gt;Class&lt;/taxonRankName&gt; &lt;taxonRankValue&gt;Bivalvia&lt;/taxonRankValue&gt; &lt;taxonomicClassification&gt; &lt;taxonRankName&gt;Order&lt;/taxonRankName&gt; &lt;taxonRankValue&gt;Filibranchia&lt;/taxonRankValue&gt; &lt;taxonomicClassification&gt; &lt;taxonRankName&gt;Genus&lt;/taxonRankName&gt; &lt;taxonRankValue&gt;Geukensia&lt;/taxonRankValue&gt; &lt;taxonomicClassification&gt; &lt;taxonRankName&gt;Species&lt;/taxonRankName&gt; &lt;taxonRankValue&gt;Geukensia demissa&lt;/taxonRankValue&gt; &lt;commonName&gt;Ribbed Mussel&lt;/commonName&gt; &lt;/taxonomicClassification&gt; &lt;/taxonomicClassification&gt; &lt;/taxonomicClassification&gt; &lt;/taxonomicClassification&gt; &lt;/taxonomicClassification&gt; &lt;/taxonomicClassification&gt; &lt;/taxonomicCoverage&gt; "],["maintenance.html", "maintenance", " maintenance This element is found at these locations (XPath): eml:eml/dataset/maintenance The dataset/maintenance/description element should be used to document changes to the data tables or metadata, including update frequency. The change history can also be used to describe alterations in static documents. The description element (TextType) can contain both formatted and unformatted text blocks. Example 16: maintenance &lt;maintenance&gt; &lt;description&gt; &lt;para&gt; Data are updated annually at the end of the calendar year. &lt;/para&gt; &lt;/description&gt; &lt;/maintenance&gt; "],["methods.html", "methods", " methods This element is found at these locations (XPath): /eml:eml/dataset/methods /eml:eml/dataset/[entity]/methods /eml:eml/dataset/[entity]/attributeList/attribute/methods General Information: In early EML versions, both “&lt;method&gt;” and “&lt;methods&gt;” elements were found, which caused confusion. In EML 2.1.0, the elements were standardized to “&lt;methods&gt;.” The &lt;methods&gt; tree appears at the dataset, entity, and attribute levels, and content is generally regarded as human readable, not machine-readable. As a ‘rule of thumb,’ methods are descriptive, and protocols are prescriptive, i.e. the methods describe what was done when collecting data, and protocols are a set of procedures or prescribed actions. A method often includes or follows a particular protocol. As a minimum, a reference to an external protocol should be given at the dataset level. However, detailed, text methods at this are preferable so that their content can be perused in a browser or indexed for searching. If further refinement is needed, methods can be defined for individual data entities or even individual &lt;attribute&gt;, although these may not be not indexed. The scope of the method defined can be tailored to match the EML document level where it is applied. For example, methods at the dataset level describe the study, for a &lt;dataTable&gt; methods might include pre-/post-processing steps, and at the attribute level, quality control. The use of methods refinement varies and keeping all methods in one place and at one level (dataset) is simpler to manage. Since they are mostly for human consumption, one detailed description of all steps taken at the dataset level is frequently sufficient and more user friendly. A description of methods contains the elements &lt;methodStep&gt;, &lt;sampling&gt;, and/or &lt;qualityControl&gt;. methodStep At least one &lt;methodStep&gt; is required under &lt;methods&gt;, and each step is a logical portion of the methods, for example, field, lab and statistical. All textual methods descriptions belong here, using &lt;description&gt; and TextType tags. At a minimum, to describe an external document two tags can be used: &lt;citation&gt; for a referral to a published document or paper, or &lt;protocol&gt;. At a minimum, the &lt;protocol&gt; requires &lt;title&gt;, &lt;creator&gt; and &lt;distribution&gt; tags, where the &lt;distribution&gt; tree may be used to refer to an online document; see the recommendations above for using that tree. Alternatively, the entire protocol may be written into EML under protocol/methodStep. instrumentation The &lt;instrumentation&gt; tag should contain a full description of the instruments used, including manufacturer, model, calibration dates and accuracy. Changes in instrumentation and dates of changes should be mentioned earlier under the &lt;description&gt;. dataSource The optional &lt;dataSource&gt; tag is for nesting an EML dataset that is input to a &lt;methodStep&gt; of the data being described, e.g., calibration information for an instrument or input parameters for a model. It also may hold the source (provenance) data when describing a derived dataset. Context Note: The &lt;dataSource&gt; element is used by the EDI repository’s provenance tracking system for linking between derived and source data packages. For more information, see additional data repository resources from EDI. sampling This optional tree can contain valuable and very specific information about the study site, coverage and frequency in addition to that listed at other levels. &lt;studyExtent&gt; provides specific information about the temporal and geographic extent of the study such as domains of interest in addition to geographic, temporal, and taxonomic coverage of the study site. &lt;studyExtent&gt; can be a surrogate for the &lt;studyAreaDescription&gt; under &lt;project&gt;. Descriptions can be either as a simple text using &lt;description&gt; or by including detailed temporal or geographic &lt;coverage&gt; elements describing discrete time periods sampled or multiple sub-regions sampled within the overall geographic bounding box that was described at the dataset level. Context Note: In the past, LTER requested that individual sampling locations be listed here (under studyExtent/spatialSamplingUnits), and some LTER sites may have applications that specifically use that XPath. However, in general use, the dataset-level geographicCoverage elements are more practical. See EDI “Other Resources,” for more information about how indexers typically handle EML. &lt;samplingDescription&gt; a text based version, similar to the sampling methods section in a journal article. qualityControl Like other trees under &lt;methods&gt;, &lt;qualityControl&gt; can be used at the dataset, entity or attribute level, whichever is appropriate. At its most basic, use the &lt;description&gt; element. Tags are also available for a &lt;citation&gt; or &lt;protocol&gt;. Example 17: methods &lt;methods&gt; &lt;methodStep&gt; &lt;description&gt; &lt;section&gt; &lt;title&gt; Pitfall trap sampling for ground arthropod biodiversity monitoring &lt;/title&gt; &lt;para&gt;Supplies used: pitfall traps (P-16 plastic Solo cups with lids) metal spades and large bulb planters (to dig holes in which to put traps) 70% ethanol (to preserve specimens) Qorpak glass jars with lids from the VWR Corporation, 120ml (4oz), cap size 58-400 (comes included), Qorpak no. 7743C, VWR catalog no. 16195-703.&lt;/para&gt; &lt;para&gt;Between 10 and 21 traps are placed at each site in siutable location.&lt;/para&gt; &lt;para&gt;All trapped taxa counted and measured (body length), most taxa identified to Family, ants to Genus&lt;/para&gt; &lt;/section&gt; &lt;/description&gt; &lt;instrumentation&gt;SBE MicroCAT 37-SM (S/N 1790); manufacturer: Sea-Bird Electronics (model: 37-SM MicroCAT); parameter: Conductivity (accuracy: 0.0003 S/m, readability: 0.00001 S/m, range: 0 to 7 S/m); last calibration: Feb 28, 2001&lt;/instrumentation&gt; &lt;instrumentation&gt;SBE MicroCAT 37-SM (S/N 1790); manufacturer: Sea-Bird Electronics (model: 37-SM MicroCAT); parameter: Pressure (water) (accuracy: 0.2m, readability: 0.0004m, range: 0 to 20m); last calibration: Feb 28, 2001&lt;/instrumentation&gt; &lt;instrumentation&gt;SBE MicroCAT 37-SM (S/N 1790); manufacturer: Sea-Bird Electronics (model: 37-SM MicroCAT); parameter: Temperature (water) (accuracy: 0.002°C, readability: 0.0001°C, range: -5 to 35°C); last calibration: Feb 28, 2001&lt;/instrumentation&gt; &lt;/methodStep&gt; &lt;sampling&gt; &lt;studyExtent&gt; &lt;description&gt; &lt;para&gt;Arthropod pit fall traps are placed in three different locations four times a year&lt;/para&gt; &lt;/description&gt; &lt;/studyExtent&gt; &lt;samplingDescription&gt; &lt;para&gt;Six traps were set in a transect at each location.&lt;/para&gt; &lt;/samplingDescription&gt; &lt;spatialSamplingUnits&gt; &lt;coverage&gt; &lt;geographicDescription&gt;site number 1&lt;/geographicDescription&gt; &lt;boundingCoordinates&gt; &lt;westBoundingCoordinate&gt;-112.234566&lt;/westBoundingCoordinate&gt; &lt;eastBoundingCoordinate&gt;-112.234566&lt;/eastBoundingCoordinate&gt; &lt;northBoundingCoordinate&gt;33.534566&lt;/northBoundingCoordinate&gt; &lt;southBoundingCoordinate&gt;33.534566&lt;/southBoundingCoordinate&gt; &lt;/boundingCoordinates&gt; &lt;/coverage&gt; &lt;coverage&gt; &lt;geographicDescription&gt;site number 2&lt;/geographicDescription&gt; &lt;boundingCoordinates&gt; &lt;westBoundingCoordinate&gt;-111.745677&lt;/westBoundingCoordinate&gt; &lt;eastBoundingCoordinate&gt;-111.745677&lt;/eastBoundingCoordinate&gt; &lt;northBoundingCoordinate&gt;33.64577&lt;/northBoundingCoordinate&gt; &lt;southBoundingCoordinate&gt;33.64577&lt;/southBoundingCoordinate&gt; &lt;/boundingCoordinates&gt; &lt;/coverage&gt; &lt;coverage&gt; &lt;geographicDescription&gt;site number 3&lt;/geographicDescription&gt; &lt;boundingCoordinates&gt; &lt;westBoundingCoordinate&gt;-112.167899&lt;/westBoundingCoordinate&gt; &lt;eastBoundingCoordinate&gt;-112.16799&lt;/eastBoundingCoordinate&gt; &lt;northBoundingCoordinate&gt;33.76799&lt;/northBoundingCoordinate&gt; &lt;southBoundingCoordinate&gt;33.76799&lt;/southBoundingCoordinate&gt; &lt;/boundingCoordinates&gt; &lt;/coverage&gt; &lt;/spatialSamplingUnits&gt; &lt;/sampling&gt; &lt;qualityControl&gt; &lt;description&gt; &lt;para&gt;All specimens are archived for future reference. Quality control during data entry is achieved with standard database techniques of pulldowns that prevent typos and constraints. Scientists inspect standard data summary statistics after data entry.&lt;/para&gt; &lt;/description&gt; &lt;/qualityControl&gt; &lt;/methods&gt; Example 18: methods, with dataSource &lt;methods&gt; &lt;methodStep&gt; &lt;description&gt; &lt;section&gt; &lt;para&gt;We utilize NPP data collected from 1906 to 2006 from the ONL LTER site. The ONL NPP data unit definition is kg/m\\^2/yr. This unit does not require conversion.&lt;/para&gt; &lt;/section&gt; &lt;/description&gt; &lt;dataSource&gt; &lt;title&gt;NPP data from ONL 1906 to 2006&lt;/title&gt; &lt;creator&gt; &lt;organizationName&gt;ONL LTER&lt;/organizationName&gt; &lt;/creator&gt; &lt;distribution&gt; &lt;online&gt; &lt;url&gt;http://metacat.lternet.edu/knb/metacat/knb-lter-onl.23.1&lt;/url&gt; &lt;/online&gt; &lt;/distribution&gt; &lt;contact&gt; &lt;organizationName&gt;ONL LTER&lt;/organizationName&gt; &lt;positionName&gt;ONL Information Manager&lt;/positionName&gt; &lt;electronicMailAddress&gt;im@onl.lternet.edu&lt;/electronicMailAddress&gt; &lt;/contact&gt; &lt;/dataSource&gt; &lt;/methodStep&gt; &lt;/methods&gt; "],["project.html", "project", " project This element is found at this location (XPath): /eml:eml/dataset/project General information: EML is one of the few specifications with a detailed tree dedicated to projects, and which can be nested, using &lt;relatedProject&gt; At its simplest, a &lt;project&gt; tree can hold a general descriptions of the project sponsoring the data package and nested if smaller sub-projects. A related project Minimally, the description of a project should include &lt;title&gt;, &lt;personnel&gt; and &lt;abstract&gt;, with the study area description and mission statement. The &lt;distribution&gt; tree should link to the project’s home page, or alternatively could link to a publication describing the project. As stated earlier, the description of elements that are reused (e.g., XML types) are discussed where they first appear, so the descriptions for these three elements (&lt;title&gt;, &lt;personnel&gt; and &lt;abstract&gt;) can be found above, under &lt;dataset&gt;, above. Two elements are unique to the &lt;project&gt; tree, &lt;fundingSource&gt; and &lt;studyAreaDiscription&gt;. &lt;fundingSource&gt; should contain the agency and grant number. It is not optional. &lt;studyAreaDiscription&gt; tree and its accompanying &lt;citation&gt; tree are optional, and may be used to describe non-coverage characteristics of the study area such as climate, geology or disturbances or references to citable biological or geophysical classification systems such as the Bailey Ecoregions or the Holdridge Life Zones. The studyAreaDiscription tree also supports multiple &lt;coverage&gt; elements that can be used to describe the geographic boundaries of individual study sites within the larger area. These can be referenced by the studyExtent/spatialSamplingUnits/referencedEntityId. The sibling &lt;descriptor&gt; tag can be used for text descriptions of the site. Example 19: project &lt;project&gt; &lt;title&gt;FSL basic monitoring program&lt;/title&gt; &lt;personnel id=&quot;pers-30&quot; system=&quot;FLS&quot;&gt; &lt;individualName&gt; &lt;salutation&gt;Dr.&lt;/salutation&gt; &lt;givenName&gt;Eva&lt;/givenName&gt; &lt;givenName&gt;M.&lt;/givenName&gt; &lt;surName&gt;Scientist&lt;/surName&gt; &lt;/individualName&gt; &lt;address&gt; &lt;deliveryPoint&gt;Department of Ecology&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;Fictitious State University&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;PO Box 111111&lt;/deliveryPoint&gt; &lt;city&gt;Ficity&lt;/city&gt; &lt;administrativeArea&gt;FI&lt;/administrativeArea&gt; &lt;postalCode&gt;11111-1111&lt;/postalCode&gt; &lt;/address&gt; &lt;role&gt;principalInvestigator&lt;/role&gt; &lt;/personnel&gt; &lt;personnel id=&quot;pers-130&quot; system=&quot;FLS&quot;&gt; &lt;individualName&gt; &lt;givenName&gt;Monica&lt;/givenName&gt; &lt;givenName&gt;D.&lt;/givenName&gt; &lt;surName&gt;Techy&lt;/surName&gt; &lt;/individualName&gt; &lt;address&gt; &lt;deliveryPoint&gt;Department for Ecology&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;Fictitious State University&lt;/deliveryPoint&gt; &lt;deliveryPoint&gt;PO Box 111111&lt;/deliveryPoint&gt; &lt;city&gt;Ficity&lt;/city&gt; &lt;administrativeArea&gt;FI&lt;/administrativeArea&gt; &lt;postalCode&gt;11111-1111&lt;/postalCode&gt; &lt;/address&gt; &lt;role&gt;principalInvestigator&lt;/role&gt; &lt;/personnel&gt; &lt;abstract&gt; &lt;para&gt;The FLS basic monitoring program consists of monitoring of arthropod populations, plant net primary productivity, and bird populations. Monitoring takes place at 3 locations, 4 times a year. Climate parameters a continuously measured at all stations.&lt;/para&gt; &lt;/abstract&gt; &lt;/project&gt; "],["entity-datatable-spatialraster-spatialvector-storedprocedure-view-otherentity.html", "[entity] = dataTable, spatialRaster, spatialVector, storedProcedure, view, otherEntity", " [entity] = dataTable, spatialRaster, spatialVector, storedProcedure, view, otherEntity This element is found at this location (XPath): /eml:eml/dataset/dataTable /eml:eml/dataset/spatialRaster /eml:eml/dataset/spatialVector /eml:eml/dataset/storedProcedure /eml:eml/dataset/view /eml:eml/dataset/otherEntity General information: If at all possible, do not publish data in dated, proprietary, binary formats such as MS-Excel, and instead, export to plain text representations such as csv. The entity types &lt;dataTable&gt;, &lt;otherEntity&gt; and &lt;view&gt; cover many commonly encountered data structures and are covered here. &lt;spatialRaster&gt;, &lt;spatialVector&gt;, &lt;storedProcedure&gt;) will be addressed in more depth in a future version of this document. Table 1 gives the general features of EML’s six entity types, to assist in selection. Table 1. Summary of the six entities in EML 2, including the type of data entity typically described with that element, how they are created and a brief description of its metadata. Element name Used for Created from Metadata features dataTable Static ASCII tables export from code, RDBMS or spreadsheets columns/rows named and defined, e.g., measurement and storage typing otherEntity Binary files, images, maps, KML, KMZ, code applications type of entity spatialRaster grid, raster cell data, remote sensing data applications, stylesheet conversions. See \"Other Resources\" spatial organization of the raster cells, their data values, and if derived via imaging sensors, characteristics about the image and its individual bands spatialVector lines, points polygons, KML (if converted), ESRI shape files applications, stylesheet conversions. See \"Other Resources\" information about the vector's geometry type, count and topology level view Data returned from a database query RDBMS similar to dataTable, plus description of the query storedProcedure Data returned from a stored procedure in a database RDBMS similar to dataTable, plus procedure’s parameters Every EML data entity has a set of elements in common, called the EntityGroup tree, which describe general information about any data resource. Other elements are provided which are unique to each entity type. The elements in the EntityGroup appear first, and are &lt;alternateIdentifier&gt; &lt;entityName&gt; &lt;entityDescription&gt; &lt;physical&gt; (including optional &lt;access&gt;) &lt;coverage&gt; &lt;methods&gt; &lt;additionalInfo&gt; &lt;alternateIdentifier&gt; (optional): The primary identifier belongs in the id attribute of the entityName (e.g., &lt;dataTable id=“xxx”&gt; , but this tag can accommodate additional identifiers that might be used, possibly from different data management systems. It is used similarly to the &lt;alternateIdentifier&gt; element at the dataset level, above. &lt;entityName&gt; (required): the name of the table, file or database table. In the early phases of EML adoption, this was often the original ASCII file name. However, a better analogy is that the &lt;entityName&gt; is a class, e.g., “FLS time series of air temperature at field station,” with its instantiation (filename) in the &lt;objectName&gt; element (see below). Context: The EDI repository requires that &lt;entityName&gt;s be unique within the entity. &lt;entityDescription&gt; This should be a longer, more descriptive explanation of the data in the entity. Like all descriptions, it is human-readable, and should help determine if it is appropriate for a particular use. The &lt;physical&gt; tree (/eml:eml/dataset/[entity]/physical) further describes the physical format of the data. &lt;objectName&gt; should be the name of the file when downloaded, or exported as text from a database. The &lt;objectName&gt; often is the filename of a file in a file system or that is accessible on the network. &lt;externallyDefinedFormat&gt; For data entities in prescribed formats (e.g., NetCDF, KML, Excel), name that format in externallyDefinedFormat/formatName. It is recommended that where possible, formats are drawn from formatNames in DataONE’s objectFormaList. Descriptions that are software-specific should include manufacturer, program, and version, e.g., “Microsoft Excel OpenXML.” &lt;distribution&gt; provides information on how the resource is distributed, and the contents of this tree was generally covered at the dataset level. However, there are a few points which will be reiterated here. The content of a &lt;url&gt; element at the entity level should deliver data, and not point to another application or use page. The &lt;url&gt;’s attribute, “function,” should have the value “download.” This is implied if the “function” attribute is omitted. As of EML 2.1, there is also an optional &lt;access&gt; element in a &lt;distribution&gt; tree at the entity level. This element is intended specifically for controlling access to the data entity separately from the metadata. For more information on using the &lt;access&gt; tree, refer to the general access discussion above. &lt;coverage&gt; provides information on the geographic, spatial and temporal coverages used in this [entity]. See the discussion at the dataset level for more information. &lt;methods&gt; provides information on the specific methods used to collect information in this [entity]. Please see the discussion at the dataset level for more information. &lt;additionalInfo&gt; is a text field for any material that cannot be characterized by the other elements for the data type. Example 20: The elements in the EntityGroup, showing the entity. &lt;dataTable&gt; &lt;entityName&gt;arthro_hab&lt;/entityName&gt; &lt;entityDescription&gt; habitat description for the sampling locations &lt;/entityDescription&gt; &lt;physical&gt; &lt;objectName&gt;fls-1.csv&lt;/objectName&gt; &lt;dataFormat&gt; &lt;textFormat&gt; &lt;numHeaderLines&gt;1&lt;/numHeaderLines&gt; &lt;numFooterLines&gt;0&lt;/numFooterLines&gt; &lt;recordDelimiter&gt;\\\\r&lt;/recordDelimiter&gt; &lt;numPhysicalLinesPerRecord&gt;1&lt;/numPhysicalLinesPerRecord&gt; &lt;recordDelimiter&gt;\\#x0A&lt;/recordDelimiter&gt; &lt;attributeOrientation&gt;column&lt;/attributeOrientation&gt; &lt;simpleDelimited&gt; &lt;fieldDelimiter&gt;,&lt;/fieldDelimiter&gt; &lt;/simpleDelimited&gt; &lt;/textFormat&gt; &lt;/dataFormat&gt; &lt;distribution&gt; &lt;online&gt; &lt;onlineDescription&gt;f1s-1 Data File&lt;/onlineDescription&gt; &lt;url function=&quot;download&quot;&gt;http://www.fsu.edu/lter/data/fls-1.csv&lt;/url&gt; &lt;/online&gt; &lt;/distribution&gt; &lt;/physical&gt; &lt;/dataTable&gt; Each data type has a specific set of elements that follow the common elements. Table 2 shows the specific trees that are applied to each of the data type. Table 2. Elements specific to each of the six entity types. Entity Type Typical Uses Elements following EntityGroup &lt;dataTable&gt; Static ASCII tables &lt;attributeList&gt; &lt;constraint&gt; &lt;caseSensitivity&gt; &lt;numberOfRecords&gt; &lt;view&gt; Data returned from a database query &lt;attributeList&gt; &lt;constraint&gt; &lt;queryStatement&gt; &lt;storedProcedure&gt; Data returned from a stored procedure in a database &lt;attributeList&gt; &lt;constraint&gt; &lt;parameter&gt; &lt;otherEntity&gt; &lt;attributeList&gt; &lt;constraint&gt; &lt;entityType&gt; &lt;spatialRaster&gt; Lines, points polygons, KML (if converted), ESRI shape files &lt;attributeList&gt; &lt;constraint&gt; &lt;spatialReference&gt; &lt;georeferenceInfo&gt; &lt;horizontalAccuracy&gt; &lt;verticalAccuracy&gt; &lt;cellSizeYDirection&gt; &lt;numberOfBands&gt; &lt;rasterOrigin&gt; &lt;rows&gt; &lt;columns&gt; &lt;verticals&gt; &lt;cellGeometry&gt; &lt;toneGradation&gt; &lt;scaleFactor&gt; &lt;offset&gt; &lt;imageDescription&gt; &lt;spatialVector&gt; Lines, points polygons, KML (if converted), ESRI shape files &lt;attributeList&gt; &lt;constraint&gt; &lt;geometry&gt; &lt;geometricObjectCount&gt; &lt;topolgyLevel&gt; &lt;spatialReference&gt; &lt;horizontalAccuracy&gt; &lt;vericalAccuracy&gt; "],["attributelist.html", "attributeList", " attributeList This element tree is found at (XPath): /eml:eml/dataset/dataTable/attributeList /eml:eml/dataset/view/attributeList /eml:eml/dataset/storedProcedure/attributeList /eml:eml/dataset/spatialRaster/attributeList /eml:eml/dataset/spatialVector/attributeList /eml:eml/dataset/otherEntity/attributeList The &lt;attributeList&gt; tree is required for all data types except for &lt;otherEntity&gt;. It describes all variables in a data entity in individual &lt;attribute&gt; elements. The description includes the name and definition of each attribute, its domain, definitions of coded values, and other pertinent information. &lt;attributeName&gt; is typically the name of a field in a data table. This is often short and/or cryptic. It is recommended that attributeNames be suitable for use as a variable, e.g., composed of ASCII characters, and that the &lt;attributeName&gt;s match the column headers of a CSV or other text table. Context: in the EDI repository, &lt;attributeName&gt;s must be unique within a data entity. &lt;attributeLabel&gt; (optional): is used to provide a less ambiguous or less cryptic alternative identification than what is provided in &lt;attributeName&gt;. &lt;attributeLabel&gt; is likely to be used as a column or row header in an HTML display. &lt;attributeDefinition&gt; gives a precise and complete definition of attribute being documented. It explains the contents of the attribute fully so that a data user can interpret the attribute accurately. &lt;storageType&gt; may be system specific, as for a RDBMS, i.e., A Microsoft SQL varchar, or Oracle datetime. This field represents a ‘hint’ to processing systems as to how the attribute might be represented in a system or language, but is distinct from the actual expression of the domain of the attribute. Non system-specific values include float, integer and string. &lt;measurementScale&gt; indicates the type of scale from which values are drawn for the attribute. EML’s attribute-unit model is described in detail; see “Other Resources.” One of the 5 scale types must be used: nominal, ordinal, interval, ratio, or dateTime, as follows: Non-numeric types: The &lt;nominal&gt; scale is used to represent named categories. Values are assigned to distinguish them from other observations. This would include a list of coded values (e.g. 1=male, 2=female), or plain text descriptions. Columns that contain strings or simple text are nominal. Example: plot1, plot2, plot3. &lt;ordinal&gt; values are categories that have a logical or ordered relationship to one another, but the magnitude of the differences between the values is not defined or meaningful. Example: Low, Medium, High. Both the nominal and ordinal scales are &lt;nonNumericDomain&gt; types, and can be either text or an enumerated list. The &lt;enumeratedDomain&gt; applies to coded values, and requires a &lt;codeDefinition&gt; or a referenced entity containing the code explanations. For &lt;textDomain&gt; an optional pattern may describe the text, e.g., a US telephone number can be described by the format “\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d.” Numeric types: &lt;interval&gt; measurements are ordinal, but in addition, use equal-sized units on a scale between values. Because the units are equal sized, these measurements are numeric. However, the starting point is arbitrary, so a value of zero is not meaningful. For example, the Celsius temperature scale uses degrees which are equally spaced, but where zero does not represent “absolute zero” (i.e., the temperature at which molecular motion stops), and 20 C is not “twice as hot” as 10 C. &lt;ratio&gt; measurements have a meaningful zero point, and ratio comparisons between values are legitimate. For example, the Kelvin scale reflects the amount of kinetic energy of a substance (i.e., zero is the point where a substance transmits no thermal energy), and so temperature measured in kelvin units is a ratio measurement. Concentration is also a ratio measurement because a solution at 10 micromolePerLiter has twice as much substance as one at 5 micromolePerLiter. The numeric types &lt;interval&gt; and &lt;ratio&gt; scales require additional tags describing the &lt;unit&gt;, &lt;numericDomain&gt;, and&lt;precision&gt;. &lt;unit&gt; Units should be described in correct physical units. Terms which describe data but are not units should be used in &lt;attributeDefinition&gt;. For example, for data describing “milligrams of Carbon per square meter,” “Carbon” belongs in the &lt;attributeDefinition&gt;, while the &lt;unit&gt; is “milligramPerMeterSquared.” &lt;standardUnit&gt; and &lt;customUnit&gt;: Unit names must be either &lt;standardUnit&gt;, from the unit dictionary included with EML (http://knb.ecoinformatics.org/software/eml/eml-2.1.0/eml-unitTypeDefinitions.html#StandardUnitDictionary) or &lt;customUnit&gt; and defined in the &lt;additionalMetadata&gt;. For general purposes, the following guidelines (from ISO recommendations) apply to &lt;customUnits&gt;: Units should be written out, not abbreviated. Unit modifiers, such as “squared,” should follow the unit being modified. For example, meterSquared is preferred, while squareMeter is improper. Units should be singular, such as “meter,” and not plural, such as “meters.” Context: EDI has adopted the LTER Unit Registry and recommends that &lt;customUnit&gt; element be used for all units with content pulled from the Unit Registry, even when the unit is already listed in the standard unit dictionary. &lt;numericDomain&gt; This tag includes elements specifying the &lt;numberType&gt; and the minimum and maximum allowable values of a numeric attribute. A measurement’s &lt;numberType&gt; should be defined as real, natural, whole or integer as explained in EML handbook: (see “Other Resources”). The &lt;bounds&gt; are theoretical or allowable minimum and maximum values (prescriptive), rather than the actual observed range in a data set (descriptive). The &lt;bounds&gt; tree is optional. &lt;precision&gt; describes the number of decimal places for the attribute. Currently, EML does not allow more than one precision value for a column. For example, a column containing lengths of fish may be measured to a precision of .01 meter for one species of fish (e.g., large), and .001 meters for a different species, but all the data on “fish length” are collected into one attribute and are measured using their appropriate precision values. For these cases precision can be omitted, but the variable precision information should be described in detail in method/methodStep. Together, the information in &lt;numericDomain&gt; and &lt;precision&gt; are sufficient to decide upon an appropriate system-specific data type for representing a particular attribute. For example, an attribute with a numeric domain from 0-50,000 and a precision of 1 could be represented in the C language using a ‘long’ value, but if the precision is changed to ‘0.5’ then a ‘float’ type would be needed. The &lt;measurementType&gt; element, &lt;dateTime&gt;, is a date-time value from the Gregorian calendar and it is recommended that these be expressed in a format that conforms to the ISO 8601 standard. An example of an allowable ISO date-time is “YYYY-MM-DD,” as in 2004-06-25, or, more fully, as “YYYY-MM-DDThh:mm:ssTZD” (eg 1997-07-16T19:20:30.45Z). The ISO standard is quite strict about the structure of date components. Since legacy data often contain non-standard dates, and existing equipment (e.g., sensors) may still be producing non-standard dates, the EML authors have provided additional allowable formats. See the EML documentation for a complete list. It is important to note that the dateTime field should not be used for recording time durations. In that case, use a unit such as seconds, nominalMinute or nominalDay, that defines the duration in terms of its relationship to SI second. The &lt;missingValueCode&gt; is optional, but should be included to describe any missing value codes present in the data set (e.g. NA, NaN, ND, 9999). The missing value code is a string, not a value, which means that the content of this field must exactly match what appears in place of data values for it to be correctly interpreted. For example, if data are output with precision .01 and with missing values formatted to “-9999.00,” then the content of the &lt;missingValueCode&gt; element must be “-9999.00” not “-9999.” The examples show two attribute trees. The first was generated from an SQL system with a defined storage type. The second &lt;attributeList&gt; includes tags for &lt;customUnits&gt;, with the Unit defined in the &lt;additionalMetadata&gt; tree. Example 21: attributeList/attribute dataTable &lt;attributeList&gt; &lt;attribute id=&quot;soil_chemistry.site_id&quot;&gt; &lt;attributeName&gt;site_id&lt;/attributeName&gt; &lt;attributeDefinition&gt;Site id as used in sites table&lt;/attributeDefinition&gt; &lt;storageType typeSystem=&quot;http://www.w3.org/2001/XMLSchema-datatypes&quot;&gt;string&lt;/storageType&gt; &lt;measurementScale&gt; &lt;nominal&gt; &lt;nonNumericDomain&gt; &lt;textDomain&gt; &lt;definition&gt;Site id as used in sites table&lt;/definition&gt; &lt;/textDomain&gt; &lt;/nonNumericDomain&gt; &lt;/nominal&gt; &lt;/measurementScale&gt; &lt;/attribute&gt; &lt;attribute id=&quot;soil_chemistry.pH&quot;&gt; &lt;attributeName&gt;pH&lt;/attributeName&gt; &lt;attributeDefinition&gt;ph of soil solution&lt;/attributeDefinition&gt; &lt;storageType typeSystem=&quot;http://www.w3.org/2001/XMLSchema-datatypes&quot;&gt;float&lt;/storageType&gt; &lt;measurementScale&gt; &lt;ratio&gt; &lt;unit&gt; &lt;standardUnit&gt;dimensionless&lt;/standardUnit&gt; &lt;/unit&gt; &lt;precision&gt;0.01&lt;/precision&gt; &lt;numericDomain&gt; &lt;numberType&gt;real&lt;/numberType&gt; &lt;/numericDomain&gt; &lt;/ratio&gt; &lt;/measurementScale&gt; &lt;/attribute&gt; &lt;attribute id=&quot;pass2001.q110&quot;&gt; &lt;attributeName&gt;q110&lt;/attributeName&gt; &lt;attributeDefinition&gt;Q110-Preference for front yard landscape&lt;/attributeDefinition&gt; &lt;storageType typeSystem=&quot;http://www.w3.org/2001/XMLSchema-datatypes&quot;&gt;float&lt;/storageType&gt; &lt;measurementScale&gt; &lt;ordinal&gt; &lt;nonNumericDomain&gt; &lt;enumeratedDomain&gt; &lt;codeDefinition&gt; &lt;code&gt;1.00&lt;/code&gt; &lt;definition&gt;1-A desert landscape&lt;/definition&gt; &lt;/codeDefinition&gt; &lt;codeDefinition&gt; &lt;code&gt;2.00&lt;/code&gt; &lt;definition&gt;2-Mostly lawn&lt;/definition&gt; &lt;/codeDefinition&gt; &lt;codeDefinition&gt; &lt;code&gt;3.00&lt;/code&gt; &lt;definition&gt;3-Some lawn&lt;/definition&gt; &lt;/codeDefinition&gt; &lt;/enumeratedDomain&gt; &lt;/nonNumericDomain&gt; &lt;/ordinal&gt; &lt;/measurementScale&gt; &lt;/attribute&gt; &lt;attribute id=&quot;att.2&quot;&gt; &lt;attributeName&gt;Year&lt;/attributeName&gt; &lt;attributeDefinition&gt;Calendar year of the observation from years 1990 - 2010&lt;/attributeDefinition&gt; &lt;storageType&gt;integer&lt;/storageType&gt; &lt;measurementScale&gt; &lt;dateTime&gt; &lt;formatString&gt;YYYY&lt;/formatString&gt; &lt;dateTimePrecision&gt;1&lt;/dateTimePrecision&gt; &lt;dateTimeDomain&gt; &lt;bounds&gt; &lt;minimum exclusive=&quot;false&quot;&gt;1993&lt;/minimum&gt; &lt;maximum exclusive=&quot;false&quot;&gt;2003&lt;/maximum&gt; &lt;/bounds&gt; &lt;/dateTimeDomain&gt; &lt;/dateTime&gt; &lt;/measurementScale&gt; &lt;/attribute&gt; &lt;attribute id=&quot;att.7&quot;&gt; &lt;attributeName&gt;Count&lt;/attributeName&gt; &lt;attributeDefinition&gt;Number of individuals observed&lt;/attributeDefinition&gt; &lt;storageType&gt;integer&lt;/storageType&gt; &lt;measurementScale&gt; &lt;interval&gt; &lt;unit&gt; &lt;standardUnit&gt;number&lt;/standardUnit&gt; &lt;/unit&gt; &lt;precision&gt;1&lt;/precision&gt; &lt;numericDomain&gt; &lt;numberType&gt;whole&lt;/numberType&gt; &lt;bounds&gt; &lt;minimum exclusive=&quot;false&quot;&gt;0&lt;/minimum&gt; &lt;/bounds&gt; &lt;/numericDomain&gt; &lt;/interval&gt; &lt;/measurementScale&gt; &lt;missingValueCode&gt; &lt;code&gt;NaN&lt;/code&gt; &lt;codeExplanation&gt;value not recorded or invalid&lt;/codeExplanation&gt; &lt;/missingValueCode&gt; &lt;/attribute&gt; &lt;attribute id=&quot;att.7&quot;&gt; &lt;attributeName&gt;cond&lt;/attributeName&gt; &lt;attributeLabel&gt;Conductivity&lt;/attributeLabel&gt; &lt;attributeDefinition&gt;measured with SeaBird Elecronics CTD-911&lt;/attributeDefinition&gt; &lt;storageType&gt;float&lt;/storageType&gt; &lt;measurementScale&gt; &lt;ratio&gt; &lt;unit&gt; &lt;customUnit&gt;siemensPerMeter&lt;/customUnit&gt; &lt;/unit&gt; &lt;precision&gt;0.0001&lt;/precision&gt; &lt;numericDomain&gt; &lt;numberType&gt;real&lt;/numberType&gt; &lt;bounds&gt; &lt;minimum exclusive=&quot;false&quot;&gt;0&lt;/minimum&gt; &lt;maximum exclusive=&quot;false&quot;&gt;40&lt;/maximum&gt; &lt;/bounds&gt; &lt;/numericDomain&gt; &lt;/ratio&gt; &lt;/measurementScale&gt; &lt;/attribute&gt; &lt;/attributeList&gt; The examples below show complete entity trees for &lt;spatialVector&gt; and &lt;spatialRaster&gt; converted via XSLT (stylesheet) from Esri metadata format. For details see “Other Resources.” Example 22: Entity and attribute information for spatialVector &lt;spatialVector id=&quot;Landuse for Ficity in 1955&quot;&gt; &lt;entityName&gt;Landuse for Ficity in 1955&lt;/entityName&gt; &lt;entityDescription&gt;This GIS layer represents a reconstructed generalized landuse map for the area of current Ficity around the time period of 1955.&lt;/entityDescription&gt; &lt;physical&gt; &lt;objectName&gt;fls-20.zip&lt;/objectName&gt; &lt;dataFormat&gt; &lt;externallyDefinedFormat&gt; &lt;formatName&gt;Esri Shapefile (zipped)&lt;/formatName&gt; &lt;/externallyDefinedFormat&gt; &lt;/dataFormat&gt; &lt;distribution&gt; &lt;online&gt; &lt;onlineDescription&gt;f1s-20 Zipped Shapefile File&lt;/onlineDescription&gt; &lt;url function=&quot;download&quot;&gt;http://www.fsu.edu/lter/data/fls-20.zip&lt;/url&gt; &lt;/online&gt; &lt;/distribution&gt; &lt;/physical&gt; &lt;attributeList id=&quot;Landuse for Ficity in 1955.attributeList&quot;&gt; &lt;attribute id=&quot;Landuse for Ficity in 1955.FID&quot;&gt; &lt;attributeName&gt;FID&lt;/attributeName&gt; &lt;attributeDefinition&gt;Internal feature number.&lt;/attributeDefinition&gt; &lt;storageType typeSystem=&quot;http://www.esri.com/metadata/esriprof80.html&quot;&gt;OID&lt;/storageType&gt; &lt;measurementScale&gt; &lt;nominal&gt; &lt;nonNumericDomain&gt; &lt;textDomain&gt; &lt;definition&gt; Sequential unique whole numbers that are automatically generated. &lt;/definition&gt; &lt;/textDomain&gt; &lt;/nonNumericDomain&gt; &lt;/nominal&gt; &lt;/measurementScale&gt; &lt;/attribute&gt; &lt;attribute id=&quot;Landuse for Ficity in 1955.Shape&quot;&gt; &lt;attributeName&gt;Shape&lt;/attributeName&gt; &lt;attributeDefinition&gt;Feature geometry.&lt;/attributeDefinition&gt; &lt;storageType typeSystem=&quot;http://www.esri.com/metadata/esriprof80.html&quot;&gt;Geometry&lt;/storageType&gt; &lt;measurementScale&gt; &lt;nominal&gt; &lt;nonNumericDomain&gt; &lt;textDomain&gt; &lt;definition&gt;Coordinates defining the features.&lt;/definition&gt; &lt;/textDomain&gt; &lt;/nonNumericDomain&gt; &lt;/nominal&gt; &lt;/measurementScale&gt; &lt;/attribute&gt; &lt;attribute id=&quot;Landuse for Ficity in 1955.Z955&quot;&gt; &lt;attributeName&gt;Z955&lt;/attributeName&gt; &lt;attributeDefinition&gt; This field signifies the landuse value for each polygon. &lt;/attributeDefinition&gt; &lt;storageType typeSystem=&quot;http://www.w3.org/2001/XMLSchema-datatypes&quot;&gt;string&lt;/storageType&gt; &lt;measurementScale&gt; &lt;nominal&gt; &lt;nonNumericDomain&gt; &lt;enumeratedDomain&gt; &lt;codeDefinition&gt; &lt;code&gt;Agriculture&lt;/code&gt; &lt;definition&gt;Agricultural land use&lt;/definition&gt; &lt;/codeDefinition&gt; &lt;codeDefinition&gt; &lt;code&gt;Urban&lt;/code&gt; &lt;definition&gt;Urbanized area&lt;/definition&gt; &lt;/codeDefinition&gt; &lt;codeDefinition&gt; &lt;code&gt;Desert&lt;/code&gt; &lt;definition&gt;Unmodified area&lt;/definition&gt; &lt;/codeDefinition&gt; &lt;codeDefinition&gt; &lt;code&gt;Recreation&lt;/code&gt; &lt;definition&gt;Recreational land use&lt;/definition&gt; &lt;/codeDefinition&gt; &lt;/enumeratedDomain&gt; &lt;/nonNumericDomain&gt; &lt;/nominal&gt; &lt;/measurementScale&gt; &lt;/attribute&gt; &lt;/attributeList&gt; &lt;geometry&gt;Polygon&lt;/geometry&gt; &lt;geometricObjectCount&gt;78&lt;/geometricObjectCount&gt; &lt;spatialReference&gt; &lt;horizCoordSysName&gt;NAD_1927_UTM_Zone_12N&lt;/horizCoordSysName&gt; &lt;/spatialReference&gt; &lt;/spatialVector&gt; Example 23: Entity and attribute information for spatialRaster &lt;spatialRaster id=&quot;fi_24k&quot;&gt; &lt;entityName&gt;fi_24k&lt;/entityName&gt; &lt;entityDefinition&gt;Ficiticiou State 7.5 Minute Digital Elevation Model&lt;/entityDefinition&gt; &lt;physical&gt; &lt;objectName&gt;fls-30.zip&lt;/objectName&gt; &lt;dataFormat&gt; &lt;externallyDefinedFormat&gt; &lt;formatName&gt;Esri binary grid&lt;/formatName&gt; &lt;/externallyDefinedFormat&gt; &lt;/dataFormat&gt; &lt;distribution&gt; &lt;online&gt; &lt;onlineDescription&gt;f1s-30 zipped raster data File&lt;/onlineDescription&gt; &lt;url function=&quot;download&quot;&gt;http://www.fsu.edu/lter/data/fls-30.zip&lt;/url&gt; &lt;/online&gt; &lt;/distribution&gt; &lt;/physical&gt; &lt;attributeList id=&quot;fi_24k.attributeList&quot;&gt; &lt;attribute id=&quot;fi_24k.ObjectID&quot;&gt; &lt;attributeName&gt;ObjectID&lt;/attributeName&gt; &lt;attributeDefinition&gt;Internal feature number.&lt;/attributeDefinition&gt; &lt;storageType typeSystem=&quot;http://www.esri.com/metadata/esriprof80.html&quot;&gt;OID&lt;/storageType&gt; &lt;measurementScale&gt; &lt;nominal&gt; &lt;nonNumericDomain&gt; &lt;textDomain&gt; &lt;definition&gt; Sequential unique whole numbers that are automatically generated. &lt;/definition&gt; &lt;/textDomain&gt; &lt;/nonNumericDomain&gt; &lt;/nominal&gt; &lt;/measurementScale&gt; &lt;/attribute&gt; &lt;attribute id=&quot;fi_24k.Cell Value&quot;&gt; &lt;attributeName&gt;Cell Value&lt;/attributeName&gt; &lt;attributeDefinition&gt;Elevation Value&lt;/attributeDefinition&gt; &lt;storageType typeSystem=&quot;http://www.esri.com/metadata/esriprof80.html&quot;&gt;Integer&lt;/storageType&gt; &lt;measurementScale&gt; &lt;ratio&gt; &lt;unit&gt; &lt;standardUnit&gt;meter&lt;/standardUnit&gt; &lt;/unit&gt; &lt;precision /&gt; &lt;numericDomain&gt; &lt;numberType&gt;integer&lt;/numberType&gt; &lt;bounds&gt; &lt;minimum exclusive=&quot;true&quot;&gt;-5193.000000&lt;/minimum&gt; &lt;maximum exclusive=&quot;true&quot;&gt;14785.000000&lt;/maximum&gt; &lt;/bounds&gt; &lt;/numericDomain&gt; &lt;/ratio&gt; &lt;/measurementScale&gt; &lt;/attribute&gt; &lt;attribute id=&quot;fi_24k.Count&quot;&gt; &lt;attributeName&gt;Count&lt;/attributeName&gt; &lt;attributeDefinition&gt;Count&lt;/attributeDefinition&gt; &lt;storageType typeSystem=&quot;http://www.esri.com/metadata/esriprof80.html&quot;&gt;Integer&lt;/storageType&gt; &lt;measurementScale&gt; &lt;ratio&gt; &lt;unit&gt; &lt;standardUnit&gt;number&lt;/standardUnit&gt; &lt;/unit&gt; &lt;precision /&gt; &lt;numericDomain&gt; &lt;numberType&gt;whole&lt;/numberType&gt; &lt;/numericDomain&gt; &lt;/ratio&gt; &lt;/measurementScale&gt; &lt;/attribute&gt; &lt;/attributeList&gt; &lt;spatialReference&gt; &lt;horizCoordSysName&gt;NAD_1927_UTM_Zone_12N&lt;/horizCoordSysName&gt; &lt;/spatialReference&gt; &lt;horizontalAccuracy&gt;not available&lt;/horizontalAccuracy&gt; &lt;verticalAccuracy&gt;not available&lt;/verticalAccuracy&gt; &lt;cellSizeXDirection&gt;30.0&lt;/cellSizeXDirection&gt; &lt;cellSizeYDirection&gt;30.0&lt;/cellSizeYDirection&gt; &lt;numberOfBands&gt;1&lt;/numberOfBands&gt; &lt;rasterOrigin&gt;Upper Left&lt;/rasterOrigin&gt; &lt;rows&gt;21092&lt;/rows&gt; &lt;columns&gt;18136&lt;/columns&gt; &lt;verticals&gt;1&lt;/verticals&gt; &lt;cellGeometry&gt;matrix&lt;/cellGeometry&gt; &lt;/spatialRaster&gt; The &lt;otherEntity&gt; data type includes the free text &lt;entityType&gt; element for naming the type of the entity. The otherEntity/physical/dataFormat/externallyDefinedFormat/formatName element stores the file format. While there is no controlled vocabulary for the content of these elements, format names can be drawn from DataONE’s objectFormaList. Table 3 provides suggestions for some common other entity formats. Table 3. Entity types and format names for some &lt;otherEntity&gt; types. Common Name Entity Type Format Name R script script R programming language script R markdown script R Markdown file PHP script script application/php JPEG image photograph JPEG PDF document document Portable Document Format "],["constraint.html", "constraint", " constraint This element tree is found at (XPath): /eml:eml/dataset/dataTable/constraint /eml:eml/dataset/view/constraint /eml:eml/dataset/spatialRaster/constraint /eml:eml/dataset/spatialVector/constraint /eml:eml/dataset/storedProcedure/constraint The &lt;constraint&gt; tree is for describing any integrity constraints between entities within a data package (e.g. tables), as they would be maintained in a relational management system. Use of the &lt;constraint&gt; tree is encouraged when data elements contain integrity constraints from a relational database. Example TO-DO shows the constraints for the &lt;attributeList&gt; in Example TO-DO. If there are constraints in which several columns are involved, these should be described in methods/qualityControl, since EML is not currently equipped to handle keys defined by multiple columns. When the &lt;constraint&gt; tree is used, all of the entities that may be referenced should be in the same package. There are six child elements: &lt;primaryKey&gt; is an element which declares the primary key in the entity to which the defined constraint pertains. &lt;uniqueKey&gt; is an element which represents a unique key within the referenced entity. This is different from a primary key in that it does not form any implicit foreign key relationships to other entities; however it is required to be unique within the entity. &lt;nonNullConstraint&gt; defines a constraint that indicates that no null values should be present for an attribute in this entity. &lt;checkConstraint&gt; defines a constraint which checks a conditional clause within an entity. &lt;foreignKey&gt; defines an SQL statement or other language implementation of the condition for a check constraint. Generally this provides a means for constraining the values within and among entities. It also provides the means to meaningfully link table for explanation of codes (de-normalization). &lt;joinCondition&gt; defines a foreign key relationship among entities which relates this entity to another’s primary key. The &lt;primaryKey&gt;, &lt;uniqueKey&gt;, &lt;nonNullConstraint&gt; require an additional &lt;key&gt; tag defining the attribute to which this constraint applies, referenced by its id attribute (described in another area). All &lt;ConstraintType&gt; entities require additional &lt;constraintName&gt; and &lt;attributeReference&gt; tags. Example 24: constraint &lt;constraint id=&quot;soil_chemistry.PRIMARY&quot;&gt; &lt;primaryKey&gt; &lt;constraintName&gt;PRIMARY&lt;/constraintName&gt; &lt;key&gt; &lt;attributeReference&gt;soil_chemistry.ID&lt;/attributeReference&gt; &lt;/key&gt; &lt;/primaryKey&gt; &lt;/constraint&gt; &lt;constraint id=&quot;soil_chemistry.FK_soil_chemistry_sites&quot;&gt; &lt;foreignKey&gt; &lt;constraintName&gt;FK_soil_chemistry_sites&lt;/constraintName&gt; &lt;key&gt; &lt;attributeReference&gt;soil_chemistry.site_id&lt;/attributeReference&gt; &lt;/key&gt; &lt;entityReference&gt;sites&lt;/entityReference&gt; &lt;/foreignKey&gt; &lt;/constraint&gt; r if (knitr::is_html_output()) '## References {-}' "],["data-package-design-for-special-cases.html", "Data Package Design for Special Cases", " Data Package Design for Special Cases Members of the working group developing these documents: S. Beaulieu, R. Brown, J. Downing, S. Elmendorf, H. Garritt, G. Gastil-Buhl, C. Gries, J. Hollingsworth, H.-Y. Hsieh, L. Kui, M. Martin, G. Maurer, A. Nguyen, J. Porter, A. Sapp, M. Servilla, T. Whiteaker In these documents we consider special cases for archiving research data based on their data type, format, or acquisition method, and recommend practices that ensure optimal re-usability of the data. Most recommendations here are aimed at improving documentation of data acquisition and processing to avoid misinterpretation. This includes the recommendation to publish raw data and/or processing code along with the data products. Others are aimed at usability in terms of data size/volume, or connecting related data. Some recommendations involve including a metadata document formatted according to a new and emerging standard (e.g., codeMeta) or a data inventory table. Data inventory tables can cross the line between metadata and data and are intended to improve discoverability and navigation of archived data. The intended audience for these best practice recommendations is the ecological research information manager (IM) community, and they are applicable to anyone operating in the context of an ecological research program. We assume that the target data repository is designed to handle ecological data, and that a given archive package will include metadata encoded in a community standard. This document references elements of the EML metadata standard, but many aspects would similarly apply to other metadata standards and these documents should be considered in the larger context of applicable metadata standard best practices. We refer to the Environmental Data Initiative (EDI) as an example data repository, though the same practices could be applied to other similar repositories. Throughout the chapters we use the term data package to refer to a published unit of data and metadata together, which is the convention at the EDI repository. At other data repositories, equivalent terms for a data package, such as dataset, may be used. A data package may contain one or more entities, such as csv tables, spatial data, processing or modeling code, and other documents (pdf, jpg, zip). A basic discussion of data package design can be found as EDI’s first phase of data publishing documentation and in the LTER Best Practices for Dataset Metadata in Ecological Metadata Language (EML). Generally, we recommend archiving entities using standard file formats that are likely to be machine readable in the future. Exceptions to this may exist where the community standard for processing particular data types relies on specialized file formats (binary, closed specification, etc.) or proprietary software. In these cases, it may be appropriate to archive specialized file types and/or a copy that has been parsed into a format (e.g. ascii) that does not require proprietary software. Table of contents Processing code Modeling datasets Images and documents Spatial data Data gathered with small, moving platforms Provenance and data in other repositories Very large datasets "],["code.html", "Code", " Code Contributors: An T. Nguyen, Tim Whiteaker Introduction This document describes best practices for archiving software, code, or scripts, such as a simulation model, data visualization package, or data manipulation scripts. The intention of these recommendations is to make research based on modeling or software more transparent rather than achieve exact reproducibility, i.e., provide sufficient documentation so that a knowledgeable person can understand algorithms, programming decisions, and their ramifications for the results, rather than run the model and obtain the same results. Examples of candidate archives for code include CoMSES Net, which focuses on sharing models related to social and ecological sciences, and Zenodo, a popular DOI-minting all-purpose repository, that can conveniently archive a specific version of code in a GitHub repository. Alternatively, code may be archived in the EDI repository, either by itself or as part of a data package. The best practices in this document cover both archiving code in EDI and referencing code archived elsewhere. While metadata for software may be described in detail using the EML &lt;software&gt; tree, there exists a project called CodeMeta which is specifically designed for software metadata. Therefore, one of the key recommendations in this document is to include a CodeMeta file when archiving software or code in EDI. Recommendations for data packages Considerations for archiving software or code If it is a model and/or a model-based dataset, please see the best practices for archiving model-based datasets. How likely is it that the code will be well maintained into the future? For example, code packages submitted to established code repositories may stay there only while they comply with all testing requirements and may be removed if not well maintained (e.g., the R package repository CRAN). If that commitment to code maintenance is unlikely, such a package should be archived in a repository without maintenance requirements. Should the code be archived as a separate package or with the data? If the code is used to generate several independent datasets it should be archived as a separate package. The software authors wishing to place it under a different license from that of the associated data, or to obtain a DOI for only the code, may be reasons to separate code and data packages. If deciding to package code separately, it may be archived on EDI or another repository. If archiving code outside of EDI, see section 2.2.4 for instructions on how to reference that code from related data packages in EDI. In most other cases, it is recommended to archive code and data together for context. Large community software packages are usually maintained and available elsewhere. However, they may undergo significant updates and it may make sense to archive the code of a certain version with the data for transparency reasons. Consider whether prior versions of a software package are available wherever that software is distributed. When choosing a repository for the code, consider the ease of the archiving process and how well the code can be described. For example, Zenodo offers an easy pathway to archive code that is currently in GitHub, though metadata requirements are very light. Following the best practices described herein, you would create a CodeMeta file if you were going to archive with EDI. This is more rigorous than Zenodo, but then your code is better described, and in a machine-readable way. Documenting software/code When describing the code with EML, include the code as an otherEntity in a data package. Although a well documented human readable text format of the code is preferred, in case of multiple scripts, and/or where directory structure is important, a zip archive may be used. For the formatName and entityType elements in EML, we recommend using format names from the DataONE format list when possible. Some format names are included in examples below. Always check the list for the most up-to-date version of these names. Example 1: EML otherEntity snippet for a script file. &lt;otherEntity&gt; &lt;entityName&gt;R script to process CTD data&lt;/entityName&gt; &lt;entityDescription&gt;Annotated RMarkdown script to process, calibrate, and flag raw CTD data.&lt;/entityDescription&gt; &lt;physical&gt; &lt;objectName&gt;BLE_LTER_CTD_QAQC.Rmd&lt;/objectName&gt; &lt;size unit=&quot;byte&quot;&gt;9674&lt;/size&gt; &lt;authentication method=&quot;MD5&quot;&gt;8547b7a63fcf6c1f0913a5bd7549d9d1&lt;/authentication&gt; &lt;dataFormat&gt; &lt;externallyDefinedFormat&gt; &lt;formatName&gt;R Markdown file&lt;/formatName&gt; &lt;/externallyDefinedFormat&gt; &lt;/dataFormat&gt; &lt;/physical&gt; &lt;entityType&gt;script&lt;/entityType&gt; &lt;/otherEntity&gt; Software License It is important to include a use license to make it clear how others can use your work. We recommend the Creative Commons “no copyright reserved” (CC0) license, which places the software in the public domain and makes it easiest for end users to adapt and use your work. If a more restrictive license is required, we recommend the Apache License, Version 2.0 license, a permissive license that allows others to reuse, modify, and redistribute your software. If a mix of data and code needs to be archived, and they each fall under different licenses, then separating them into different packages is advisable to eliminate ambiguity on which license applies to which portion of a data package. When a license other than a public domain dedication is used, then in addition to specifying the license in the metadata (see the “intellectualRights” element in EML), consider including a copy of the license at the beginning of the code files themselves so that the license is readily apparent to end users who peruse the code. CodeMeta Include a CodeMeta JSON file for all code that is archived in EDI. The CodeMeta file should be named “codemeta.json” and listed as an EML otherEntity. The formatName should be “JavaScript Object Notation (JSON) file,” the entityType should be “metadata,” and the entityDescription should indicate that this is a CodeMeta file for a given software or script in the data package. For unnamed projects, e.g., one-off scripts for data processing, analysis, and/or visualisation, a CodeMeta file might appear to be overkill; however, CodeMeta files are simple to generate, and we recommend the below bare minimum. If there are multiple scripts each in their own otherEntity tag, we recommend aggregating information about them into one codemeta.json. Example 2: Minimum recommended codemeta.json example for unnamed projects. { &quot;@context&quot;: [&quot;https://doi.org/10.5063/schema/codemeta-2.0&quot;, &quot;http://schema.org&quot; ], &quot;@type&quot;: &quot;SoftwareSourceCode&quot;, &quot;description&quot;: &quot;RMarkdown script to calibrate and flag raw CTD data.&quot;, &quot;author&quot;: { &quot;@type&quot;: &quot;Person&quot;, &quot;givenName&quot;: &quot;Christina&quot;, &quot;familyName&quot;: &quot;Bonsell&quot;, &quot;email&quot;: &quot;cbonsell@utexas.edu&quot;, &quot;@id&quot;: &quot;https://orcid.org/0000-0002-8564-0618&quot; }, &quot;keywords&quot;: [&quot;calibration&quot;, &quot;CTD&quot;, &quot;RMarkdown&quot;], &quot;license&quot;: &quot;https://unlicense.org/&quot;, &quot;dateCreated&quot;: &quot;2013-10-19&quot;, &quot;programmingLanguage&quot;: { &quot;@type&quot;: &quot;ComputerLanguage&quot;, &quot;name&quot;: &quot;R&quot;, &quot;version&quot;: &quot;3.6.2&quot;, &quot;url&quot;: &quot;https://r-project.org&quot; } } Example 3: sample otherEntity metadata for example 2â€™s codemeta.json. &lt;otherEntity&gt; &lt;entityName&gt;CodeMeta file for BLE_LTER_CTD_QAQC.Rmd&lt;/entityName&gt; &lt;entityDescription&gt;CodeMeta file for annotated RMarkdown script to process, calibrate, and flag raw CTD data.&lt;/entityDescription&gt; &lt;physical&gt; &lt;objectName&gt;codemeta.json&lt;/objectName&gt; &lt;size unit=&quot;byte&quot;&gt;702&lt;/size&gt; &lt;authentication method=&quot;MD5&quot;&gt;8547b7a63abc6c1f0913a5bd7549d9d1&lt;/authentication&gt; &lt;dataFormat&gt; &lt;externallyDefinedFormat&gt; &lt;formatName&gt;application/json&lt;/formatName&gt; &lt;/externallyDefinedFormat&gt; &lt;/dataFormat&gt; &lt;/physical&gt; &lt;entityType&gt;CodeMeta&lt;/entityType&gt; &lt;/otherEntity&gt; For named projects, also include the software name, and the version if applicable. The example below shows some additional metadata you can include. See also the more complete codemetar example and the available CodeMeta terms. Example 4: A more complete CodeMeta example for named projects. Example taken from the CodeMeta project Github with edits for brevity. { &quot;@context&quot;: [&quot;https://doi.org/10.5063/schema/codemeta-2.0&quot;, &quot;http://schema.org&quot; ], &quot;@type&quot;: &quot;SoftwareSourceCode&quot;, &quot;name&quot;: &quot;codemetar: Generate &#39;CodeMeta&#39; Metadata for R Packages&quot;, &quot;description&quot;: &quot;A JSON-LD format for software metadata&quot;, &quot;author&quot;: [{ &quot;@type&quot;: &quot;Person&quot;, &quot;givenName&quot;: &quot;Carl&quot;, &quot;familyName&quot;: &quot;Boettiger&quot;, &quot;email&quot;: &quot;cboettig@gmail.com&quot;, &quot;@id&quot;: &quot;https://orcid.org/0000-0002-1642-628X&quot; }, { &quot;@type&quot;: &quot;Person&quot;, &quot;givenName&quot;: &quot;MaÃ«lle&quot;, &quot;familyName&quot;: &quot;Salmon&quot;, &quot;@id&quot;: &quot;https://orcid.org/0000-0002-2815-0399&quot; } ], &quot;codeRepository&quot;: &quot;https://github.com/ropensci/codemetar&quot;, &quot;dateCreated&quot;: &quot;2013-10-19&quot;, &quot;license&quot;: &quot;https://spdx.org/licenses/GPL-3.0&quot;, &quot;version&quot;: &quot;0.1.8&quot;, &quot;programmingLanguage&quot;: { &quot;@type&quot;: &quot;ComputerLanguage&quot;, &quot;name&quot;: &quot;R&quot;, &quot;version&quot;: &quot;3.5.3&quot;, &quot;url&quot;: &quot;https://r-project.org&quot; }, &quot;softwareRequirements&quot;: [{ &quot;@type&quot;: &quot;SoftwareApplication&quot;, &quot;identifier&quot;: &quot;R&quot;, &quot;name&quot;: &quot;R&quot;, &quot;version&quot;: &quot;&gt;= 3.0.0&quot; }, { &quot;@type&quot;: &quot;SoftwareApplication&quot;, &quot;identifier&quot;: &quot;git2r&quot;, &quot;name&quot;: &quot;git2r&quot;, &quot;provider&quot;: { &quot;@id&quot;: &quot;https://cran.r-project.org&quot;, &quot;@type&quot;: &quot;Organization&quot;, &quot;name&quot;: &quot;Comprehensive R Archive Network (CRAN)&quot;, &quot;url&quot;: &quot;https://cran.r-project.org&quot; } } ], &quot;keywords&quot;: [&quot;metadata&quot;, &quot;codemeta&quot;, &quot;ropensci&quot;] } Metadata to enable reproducibility When archiving software, we strongly recommend including a user guide with installation and usage instructions if such would not already be apparent to the typical user. Take into account that the user might not have access to certain inputs that the software/scripts require. Include when feasible at least some example data, and configure the script so that it is ready to run with the example data. Aside from the software/code itself and its dependencies, other pieces of information may be important should a user wish to reproduce results, such as the operating system and version and the system locale. Include this information in the data packageâ€™s methods/methodStep/description. For certain tools, there are ways to easily generate this information, e.g., a call to sessionInfo() in the R console. If the system outputs this information in a standardly formatted plain text file, that might be included as an otherEntity. Linking code and data There are a few solutions for providing explicit machine-readable linkages between different entities/packages (the distinction between code/data doesnâ€™t matter too much here). For most cases we recommend the simplest approach, which is to use the methods/methodStep/description element of EML. More advanced users may wish to utilize the other solutions described herein. Descriptive approach In the dataset methods/methodStep/description element, include verbal descriptions such as “results.csv was derived from raw_data.csv using script.R” and repeat for all entities. If code and data reside in different packages, be sure to specify that. The EML dataSource element Nested under methods/methodStep, dataSource elements describe other data packages that serve as source for the current package. dataSource looks like a mini-EML tree describing the source data. Example: ecocomDP packages list the original packages under dataSource. dataSource does not describe relationships between entities in the same package, and as far as we know there is no explicit way in EML to do so. ProvONE ProvONE is a model developed by DataONE affiliates for provenance or denoting relationships between data entities. Each package on DataONE is described by a science metadata document (e.g., EML, ISO, FGDC) and a resource map document following ProvONE. The resource map powers a nice display of data relationships (see this package on the Arctic Data Center). This handles both relationships between entities in the same package and entities residing in different packages. However, note that EDI currently does not utilize this model. External software Large community-backed tools or proprietary software such as ArcGIS Pro or Microsoft Excel do not need to be archived. However, if they have had any impact on the final data (e.g., ArcGIS Pro was used to modify spatial rasters), the EML methods section should describe the routines performed. Within the data package, indicate linkage to external software as follows. Briefly describe the software/code and its relationship to the data in EMLâ€™s methods/methodStep/description element. Names of all software used. Include both the common acronym and the full spelling. The URL(s) to all models/software used. Stable, persistent URLs pointing to exact version(s) are preferable, rather than generic links such as a project homepage. If the archived model has a DOI, then include a full citation to the model in the methods/methodStep/description text. The exception to this is when referencing tools such as Excel that have achieved global household name status. Broadly, the system setup used, if relevant. Information on exact versions for all code used (including dependencies). This is important, e.g., ArcGIS Pro 2.4.1 is very different from ArcGIS for Desktop 10.7.1. Different systems have methods to easily generate this information, e.g. a call to sessionInfo() in the R console. Consider, if applicable, to archive the “runfile” as its own data entity within the data package, i.e., the script(s) that sets parameters and/or calls on functions imported from external software. Example 5: EML method description referring to external software. &lt;methods&gt; &lt;methodStep&gt; &lt;description&gt; &lt;para&gt; The seagrass coverage raster was created in ArcGIS Pro (version 2.4.3, by Esri) using the IDW geoprocessing tool on sampling_points.csv with a power of 2 and the nearest 12 points. &lt;/para&gt; &lt;para&gt; The raster was then refined using the seagrass-refiner package with the auto-refine option checked (Smith, 2017). &lt;/para&gt; &lt;para&gt; Smith, J. (2017). seagrass-refiner: a package that does the cool seagrass stuff, Version 1.2, Zenodo. https://doi.org/this-is/a-fake-doi, 2017. &lt;/para&gt; &lt;/description&gt; &lt;/methodStep&gt; &lt;/methods&gt; Resources CodeMeta website CodeMeta generator for creating CodeMeta CodeMeta crosswalks for a number of popular software CodeMeta terms you can use for describing software A description of some software licenses Best practices document to archiving model-based datasets ProvONE documentation W3C PROV-O documentation Licensing software as part of an EDI data package "],["model-based-datasets.html", "Model-Based Datasets", " Model-Based Datasets Contributors: An T. Nguyen, Tim Whiteaker, Corinna Gries Introduction This document includes recommendations for archiving data packages composed of model-based datasets. These datasets may include the model code itself, input data, model parameter settings, and output data. The range of cases for model-based datasets includes small one-off model code specific to one research question, through various code packages which are maintained in community repositories as long as they meet requirements (e.g., CRAN for R packages), to large community models maintained by groups of programmers and users. The intention of these recommendations is to make research based on modeling more transparent rather than achieve exact reproducibility, i.e., provide sufficient documentation so that a knowledgeable person can understand algorithms, programming decisions, and their ramifications for the results, rather than run the model and obtain the same results. It is not always easy to determine who among project personnel (IMs, scientists, programmers) is responsible for the different components of a model-based dataset. This is best decided on a case-by-case basis. A common division is that the code authors annotate the code, and the IM handles the archiving and linkage to data product(s); partially except in cases of large community models. Recommendations for data packages Figure 1: Flowchart for considering archival paths for various model components. Referencing models in EML For data packages related to a model, whether the model is archived within the same data package or not, indicate linkage to the model in EML following the best practices for archiving code (see the section on linking code and data). Example 1: EML snippet relating data to models via the method description: &lt;methodStep&gt; &lt;description&gt; &lt;para&gt;This methodStep contains data provenance information as specified in the LTER EML Best Practices. Each dataSource element here lists entity-specific information and links to source data used in the creation of this derivative data package.&lt;/para&gt; &lt;/description&gt; &lt;dataSource&gt; &lt;title&gt;Source dataset title&lt;/title&gt; &lt;creator&gt; &lt;individualName&gt; &lt;givenName&gt;first name&lt;/givenName&gt; &lt;surName&gt;last name&lt;/surName&gt; &lt;/individualName&gt; &lt;organizationName&gt;organization name&lt;/organizationName&gt; &lt;electronicMailAddress&gt;email@some.edu&lt;/electronicMailAddress&gt; &lt;/creator&gt; &lt;distribution&gt; &lt;online&gt; &lt;onlineDescription&gt;This is a link to an external online data resource (describe resource and repository location).&lt;/onlineDescription&gt; &lt;url function=&quot;information&quot;&gt;https://pasta.lternet.edu/package/metadata/eml/knb-lter-ntl/80/2&lt;/url&gt; &lt;/online&gt; &lt;/distribution&gt; &lt;contact&gt; &lt;positionName&gt;Information Manager&lt;/positionName&gt; &lt;organizationName&gt;organization name&lt;/organizationName&gt; &lt;electronicMailAddress&gt;infomgr@some.edu&lt;/electronicMailAddress&gt; &lt;/contact&gt; &lt;/dataSource&gt; &lt;/methodStep&gt; Model code The model used to produce certain data needs to be well documented and linked from the resulting data product(s). However, it is not always easy to decide where and how to archive the code, and whether or not in conjunction with the data product(s). We outline in sections below three common code archiving options. Note that these scenarios (model code archived with data, or standalone in EDI, or elsewhere) are not mutually exclusive. Any project that involves code might make use of both established and custom software hosted on many different platforms, and might use some or all archiving options. To decide between archiving options, consider the questions listed in best practices for publishing code. Model code and data in the same package The goal of this practice is to ensure transparency of the data, and it applies to one-off models developed for the associated data, or occasionally to larger code bases for the reasons outlined in best practices for archiving code. Include the code as a dataset/otherEntity. Additionally, it is recommended to include a CodeMeta file, which can also be handled and documented in EML as dataset/otherEntity. CodeMeta is a metadata standard for software and code compatible with schema.org. Refer to best practices for archiving code for how to document the code and create CodeMeta. Model code as standalone package If the model has been used to generate several datasets, i.e., is more widely applicable, it can be archived as its own package in EDI and assigned a DOI. Include the code as a dataset/otherEntity. Additionally, it is recommended to include a CodeMeta JSON-LD file, which can also be handled and documented in EML as dataset/otherEntity. CodeMeta is a metadata standard for software and code compatible with schema.org. Refer to best practices for archiving code for how to document the code and create CodeMeta. Model code archived/maintained elsewhere This might include complex community models/software maintained by many people, published and actively maintained R/Python packages, etc., or simply code archived in another repository such as CoMSES Net. It may sometimes be advisable to archive a copy of the model code with the data, even if it appears to be maintained elsewhere. See recommendations above for referencing models in EML. Model input and output data These are considered data entities, which should be handled according to EML best practices for corresponding data types. However, if the resulting datasets are very large, one may consider if input/output from all individual model runs need to be archived. Are there specific model run results that are more useful for non-modelers? For example: results from model runs leading to a journal publication. Very large model inputs/outputs may need to be archived offline. Refer to best practices for offline data. If the model requires a specific folder structure, you can zip model input files within the package to preserve that folder structure. A disadvantage of this approach is that you cannot elegantly describe each file with EML. The EarthCube Research Coordination Network, “What About Model Data?” group is working on a rubric to help you determine how much model output data to save, based on assorted criteria on reproducibility/value of the data. Learn more about that group and their rubric on their Model Data RCN website. Researchers at the Department of Energyâ€™s Environmental Systems Science are also working on assessing model archiving needs. In this preprint, Simmonds et al. 2020 discuss feedback from communications with modellers and propose preliminary solutions. With regards to input/output data, their feedback indicates two opposite opinions: some feel the whole gamut of raw to aggregated outputs needs to be archived, while others advocate for only high-level outputs corresponding to publication figures. They also found that spin-up simulations were not considered a high priority for archiving. See section 2.3 What is worth archiving and for how long does it remain useful? Model parameters Include model parameters whenever applicable. If code/input/output from multiple model runs are archived, make sure to archive all corresponding sets of parameters, and be explicit in linking the different components together. Consider archiving model parameter files as their own data object(s) in both their native format and as a text (non-binary) version. If the ‘runfile’ will be archived, consider including the parameters within that file with appropriate annotations. Example data packages in EDI Dataset Title Description EDI Package ID North Temperate Lakes LTER General Lake Model Parameter Set for Lake Mendota, Summer 2016 Calibration Parameters for specific GLM runs. GLM is a large community model, not managed and archived in EDI knb-lter-ntl.348.2 SBC LTER: Regional Oceanic Modeling System (ROMS) Setup Files, Code, and Lagrangian Model Setup Files All the necessary code, grid, forcing, initial, and boundary condition files for running the UCLA version of the Regional Oceanic Modeling System (ROMS) for the Santa Barbara Channel knb-lter-sbc.126.1 Lake thermal structure drives inter-annual variability in summer anoxia dynamics in a eutrophic lake over 37 years Dataset to run a 37-year simulation (1979-2015) of the Lake Mendota lake ecosystem using the vertical 1D GLM-AED2 model. knb-lter-ntl.396.1 Resources Janssen, Marco A., Lilian Na’ia Alessa, Michael Barton, Sean Bergin and Allen Lee (2008). â€˜Towards a Community Framework for Agent-Based Modellingâ€™. Journal of Artificial Societies and Social Simulation 11(2)6 http://jasss.soc.surrey.ac.uk/11/2/6.html. Simmonds, Maegen, William J. Riley, Shreyas Cholia, and Charuleka Varadharajan (2020). ‘Addressing Model Data Archiving Needs for the Department of Energyâ€™s Environmental Systems Science Community.’ EarthArXiv (preprint). https://doi.org/10.31223/osf.io/acdk4. See sections 2.3 What is worth archiving and for how long does it remain useful?, discussed above, plus 2.4 Model data archiving protocol, where the authors argue for better standardized reporting format for model data, e.g., top-level metadata and directory structure at a minimum. Section 4.1 Developing Model Data Archiving Guidelines proposes an organization scheme for model data. "],["images-and-documents-as-data.html", "Images and Documents as Data", " Images and Documents as Data Contributors: Renee F. Brown (lead), Stace Beaulieu, Sarah Elmendorf, Gastil Gastil-Buhl, Corinna Gries, Li Kui, Mary Martin, Greg Maurer, John Porter, Tim Whiteaker Introduction This chapter describes best practices for archiving images and other documents as data. The Environment Ontology (ENVO) defines a document as ‘a collection of information content entities intended to be understood together as a whole.’ Common examples include still images, audio and/or video multimedia files, field notebooks, written interview notes or transcribed oral accounts, historical document collections, and ‘paper’ maps (non-digitized maps). For images that are already handled by specialized repositories (e.g., phenocam images, specimen images) refer to Data in Other Repositories, for additional information on how to handle images from uncrewed (underwater or aerial) vehicles refer to Data Gathered with Small Moving Platforms, and for geospatial imagery refer to Spatial Data. Recommendations for data packages Reasons to archive documents as data Enhance the credibility of associated datasets. Many document types (field notes, still images, etc.) often provide additional metadata that cannot easily be encapsulated in the associated dataset(s) or were not considered important at the time of transcription. As such, these documents may provide opportunities to rectify transcription errors, retrospectively provide explanations of unusual data, and/or include additional observational or measured data, such as opportunistic measurements or calibration parameters. Provide opportunities for new analyses. New analytical methods may be employed on archived documents (especially still images) or documents that were never archived previously because the cost-to-benefit ratio was considered too high (e.g., pilot projects). Improve ease of access. In distributed projects, access to original and/or ‘hard-copy’ documents may be limited to a particular institution or subset of people. By digitally archiving these documents in a data repository, the data become more findable, accessible, interoperable, and reusable (FAIR). Considerations for data package structure Balance file size and number of files. A data package may contain document files individually or bundled as a compressed archive (e.g., zip). The decision of how to bundle documents into compressed archives and then into data packages should be guided by the overall goal of making data usable for the intended purpose of the documents. In most cases, this would involve finding specific documents by, for example, the date or location of the acquisition, or some other aspect of interest. In addition, the effort of documenting documents (each individually vs. in groups) has to be taken into account. Also see Large Data Sets. Document grouping. Data packages, or compressed archives within data packages, may be grouped spatially (e.g., by location) and/or temporally (e.g., by date, season, or year). For example, data outputs from a stationary camera may be archived in annual data packages, each containing monthly compressed archives if the number of images is large. While moving camera outputs may also be archived annually, these data packages may instead include compressed archives containing all still images for a single location. Document naming. To maximize searchability, document names should be unique and meaningful for a data reuser. It is recommended that individual documents be named according to their content, and compressed archives include date, location, and other relevant information in the filename. Data inventory table. An inventory table providing the structure and organization of the included document entities or groups of documents (see Table 4.1) is recommended, especially for larger collections of documents within a data package. The inventory table serves as an additional source of metadata and may also be used to link specific documents to additional information. Archival frequency. One should strive for archiving a fully processed group of documents when no more updates are expected (e.g., after a field season or annually) due to the large volume of documents to be handled repeatedly for each update. Linking to related data packages. In the case where the documents are useful to understanding another data package and vice versa (e.g., met station visitation logs and met station time series data), it is recommended to link the complementary data package in the methods section of both datasets. Alternatively, include the document(s) or compressed archive(s) in the existing dataset as otherEntity, as described in the next section. Documenting data packages Ecological Metadata Language All data packages require good discovery-level metadata in Ecological Metadata Language (EML), which should be assembled using standard documented best practices. Documents (including compressed archives) should be included as otherEntity in the data package (e.g., see Example 4.1). Refer to the most recent version of EML Best Practices (currently v3) for guidance regarding the formatName and entityType EML elements. If a format for your document type is not covered, it is recommended to use the appropriate MIME type, if available. Example 1: EML otherEntity snippet for a pdf file &lt;otherEntity&gt; &lt;entityName&gt;site date&lt;/entityName&gt; &lt;entityDescription&gt;Field notes at site and date.&lt;/entityDescription&gt; &lt;physical&gt; &lt;objectName&gt;site_date.pdf&lt;/objectName&gt; &lt;size unit=&quot;byte&quot;&gt;9674&lt;/size&gt; &lt;authentication method=&quot;MD5&quot;&gt;8547b7a63fcf6c1f0913a5bd7549d9d1&lt;/authentication&gt; &lt;dataFormat&gt; &lt;externallyDefinedFormat&gt; &lt;formatName&gt;Portable Document Format&lt;/formatName&gt; &lt;/externallyDefinedFormat&gt; &lt;/dataFormat&gt; &lt;/physical&gt; &lt;entityType&gt;application/pdf&lt;/entityType&gt; &lt;/otherEntity&gt; The EML metadata should also include appropriate keywords describing the general purpose of the document or compressed archive (e.g., ice phenology, community composition, stream hydrology, etc.). For example, for still images, it is recommended to include keyword: image with the semantic annotation from the Information Artifact Ontology (IAO) : **Term IRI:** [http://purl.obolibrary.org/obo/IAO_0000101](http://purl.obolibrary.org/obo/IAO_0000101) **Definition:** An image is an affine projection to a two dimensional surface, of measurements of some quality of an entity or entities repeated at regular intervals across a spatial range, where the measurements are represented as color and luminosity on the projected surface. Note, IAO includes at least one subcategory for image (e.g., photograph). It is recommended the most specific applicable concept be used. Data Inventory Table We recommend that an additional level of metadata be provided through a data inventory table that effectively serves as a document catalog (see Table 4.1). The detail provided in this table should be guided by the same principles as stated above – to enable optimal usability of the documents. For example, still images from a stationary camera require latitude and longitude only in the EML file, not for each individual image. However, images from a moving camera may need that information for every image, or at least for every location (e.g., site, quadrat, transect). Additionally, Exif metadata from photographic images may be programmatically extracted to supplement the inventory table (refer to the Tips and Tricks section of Data Gathered with Small Moving Platforms). The data inventory table should be structured such that each column represents a particular attribute, described in EML as a dataTable entity, and each row represents an individual document or a compressed archive of a group of documents. At minimum, the table should include an attribute for the document/archive filename, as well as any other essential attributes that vary per each document/archive. Additional attributes may include information on the date and/or time, but for this information to be useful, be consistent and use a controlled vocabulary for these fields so that a user can effectively search on them. Table 1: Data inventory table structure. Column Attribute Description Filename Filename of each document or compressed archive, including file extension (e.g., ‘site_date.jpg’). For compressed archives, include the relative path of the document, with respect to the uncompressed directory structure (e.g., ‘2018/SITE3/quadrat4.jpg’). Link/URL/URI Link to download a document if it is available on a different system (also see Data in Other Repositories). Persistent identifiers are recommended, if available. Creator(s) Name(s) of the creator(s) of the original document (e.g., photographer, field technician, interviewer). Multiple creators should be entered into a single cell using the pipe delimiter. Datetime Date (and time) associated with the document, in ISO 8601 format (e.g., 2007-04-05T12:30-02:00). Project specific datetime attributes One or more appropriately labeled columns containing project specific date and time information for easier search and retrieval of documents (e.g., year, season, campaign). Location One or more location columns as appropriate, such as latitude and longitude in decimal degrees, site name, transect name, altitude, depth, habitat, etc. Document specific attributes One or more columns as appropriate to the document type, such as weather conditions, organism name, instrument type, etc. Example data packages in EDI Each of the Environmental Data Initiative (EDI) data packages listed below include images or other documents as data. Some of these packages contain data inventory tables (as dataTable entities) described in the EML metadata. Table 2: Data packages in EDI providing examples of best practices from this document. Dataset Title Description EDI Package ID Annual ground-based photographs taken at 15 net primary production (NPP) study sites at Jornada Basin LTER, 1996-ongoing Compressed archives of images grouped by year. Includes data inventory file. knb-lter-jrn.210011005.105 McMurdo Dry Valleys LTER: Landscape Albedo in Taylor Valley, Antarctica from 2015 to 2019 Compressed archives of aerial images, grouped by flight date, and associated reflectance data. knb-lter-mcm.2016.2 MCR LTER: Coral Reef: Computer Vision: Multi-annotator Comparison of Coral Photo Quadrat Analysis 5090 coral reef survey images, and 251,988 random-point annotations by coral ecology experts. knb-lter-mcr.5013.3 Abundance and biovolume of taxonomically-resolved phytoplankton and microzooplankton imaged continuously underway with an Imaging FlowCytobot along the NES-LTER Transect in winter 2018 144,281 images from a plankton imaging system with annotations and extracted size data. knb-lter-nes.9.1 Calling activity of Birds in the White Mountain National Forest: Audio Recordings (2016 and 2018) Compressed archive containing 410 audio files in wav format. Includes data inventory table. knb-lter-hbr.268.1 Resources Considerations for digitizing documents Following are some general considerations and recommendations for digitizing paper or other ‘hard-copy’ documents for archival. This is not meant to be an exhaustive list. For further and more detailed information, please refer to the U.S. National Archives and Records Administration (NARA)â€™s Technical Guidelines for Digitizing Archival Materials for Electronic Access. Effort. The decision to digitize documents, as well as the digitization method, involves trade-offs in the accessibility and ease of using particular hardware and/or software technologies, the quality of the digitization, and the overall effort spent. Digitization efforts may be significant, for example, when dealing with a large number of documents requiring meaningful file names, text recognition, and/or high resolution for improved accessibility. Equipment. Instruments for digitizing hard-copy documents range from high resolution scanners (less accessible, less user-friendly, more expensive, better quality) to smartphone cameras (ubiquitous, easy-to-use, lower quality). For example, taking a smartphone image in the field may be utilized for quick and easy digitization of field notes. Document resolution and file size. This is an important consideration that should be guided by the content and purpose of the document. Detailed paper maps should probably be scanned at high resolution and large file size, while field sheets may not need as much detail. Optical Character Recognition (OCR): When digitizing documents that include text, we recommend using scanning or other software with OCR capabilities (e.g., Adobe, ABBYY, Tesseract) to convert the text into machine readable characters so that the documents are searchable and thus, more usable. OCR does not work well for handwritten text, older fonts, or documents with busy backgrounds (speckled, dirty, faded, etc.). Sensitive Information and Human Subjects: Regardless of the digitization method, one should be mindful of sensitive information that shouldnâ€™t be archived or otherwise redacted (e.g., photographs of human subjects, field notebooks containing personal messages, gate combinations, and/or telephone numbers). In all cases in which human subjects are involved, Institutional Review Board (IRB) restrictions must be heeded. A signed IRB consent form for the associated research project represents a contract between researcher and human subject. It is important to note that IRB restrictions can differ among research studies within the same project. For further information, see the EDI Data Initiative Data Policy. While transcription is a digitization method that can be performed on certain types of documents (e.g., audio/video recordings, field notebooks) and can enhance search capabilities, transcript generation requires substantially more effort than other digitization methods, and is prone to error. Moreover, in the case where the original documents contain drawings, transcripts may be incomplete or otherwise inaccurate. Thus, we recommend digitizing documents by other means, using the considerations described above. "],["spatial-data.html", "Spatial Data", " Spatial Data Contributors: Tim Whiteaker, John Porter, Mary Martin Introduction This document/chapter contains recommendations on data package structure and metadata for spatial datasets. Over the timeline of Long Term Ecological Research (LTER) Network?s use of the Ecological Metadata Language (EML), both spatial data formats and data curation options have evolved. In this document, focus on best practices that can be widely adopted with the goal of enhancing data discoverability and usability, and the understanding that there are multiple solutions to creating these data packages. Recommendations for data packages Considerations for archiving spatial data Data formats To maximize reuse, avoid proprietary formats. The formats listed below can be read or imported by most mainstream GIS programs or with code using libraries such as GDAL. Strongly recommended formats: GeoTIFF - An open format for storing spatial raster data and metadata in a TIFF file. GeoPackage - A standard format from the Open Geospatial Consortium (OGC) for storing vector and raster data in a SQLite database file. Some other formats to consider are listed below. KML/KMZ - Keyhole Markup Language (KML) file and its zipped version for storing vector data. This format was popularized by Google Earth and is now an OGC standard. KML is best visualized in Google software and may not render as well in other GIS software. GeoJSON - A format for storing vector data as text in JavaScript Object Notation (JSON). GeoJSON data are limited to the WGS84 coordinate system. netCDF/HDF5 - binary formats originally designed for storing multidimensional arrays of spatial data typically organized onto a grid, but which now can accommodate vector data following the NetCDF Climate and Forecast Conventions (version 1.8 or higher). A couple of Esri formats are worth mentioning and are listed below. File geodatabase - One of Esri’s formats for storing vector and raster information. Several feature classes and rasters can be stored in this folder and file based structure. GDAL’s OpenFileGDB driver enables non-Esri software to view at least the data layers in a file geodatabase, but usage of more advanced file geodatabase components such as topology rules or geometric networks may not be available outside of Esri software. Field types may not be imported correctly either. Export to GeoPackage instead, unless geodatabase is the only format that supports the advanced representation of your GIS data. Just know that you limit potential reuse of your data if you use this format. Shapefile - A legacy format for vector data which is widely supported. Be aware of shapefile limitations when considering this format. A shapefile consists of several individual files; include them as a single zip file in the data package. If the package has more than one shapefile, create a separate zip file for each shapefile. Although other open formats exist, their implementation in popular GIS software may be less common. If a proprietary format must be used to capture the full meaning of the data, consider also including a version of the data in an open format such as a simple data table along with metadata explaining its limitations in that format, or instructions on how to utilize the proprietary format. For example, an Esri layer package could be used when including recommended symbols for drawing vector features in a GIS is desired, in which case one could note that the vector data can be extracted by treating the layer package as a zip file. Formats that are composed of more than one file, such as shapefiles, should be zipped. Include one dataset per zip file. For example, if you have 10 shapefiles, you would create 10 zip files. Documenting spatial data packages Document as spatial[Raster, Vector] vs. otherEntity in EML There is a noticeable divergence in EDI spatial data packages, specifically, in the use of otherEntity vs spatial[Raster,Vector]. Here we discuss pros and cons of why one might choose to document spatial data with one type of EML entity over another. Either method is acceptable, and we recommend using spatial[Raster,Vector] when feasible. The documentation that follows provides best practices that will maximize discoverability and useability of spatial data, regardless of the entity type used. otherEntity Pros EML preparation is simpler than with the spatial EML types Allows aggregated data structures (e.g., file geodatabases) Cons Spatial data stored as &lt;otherEntity&gt; might be harder to discover because it may be difficult to determine if data in an &lt;otherEntity&gt; is spatial data or some other type when searching or browsing There is currently no controlled keywording to identify spatial data files that are included as otherEntity in EML Tabular attributes of geometric entities may not be described in detail Units (latitude/longitude vs meters vs feet) and projections may not be identified spatial[Raster,Vector] Pros EML more fully describes vector attributes There is a well documented path from Esri metadata to EML An EML metadata search (on EDI or elsewhere) clearly identifies these as spatial datasets through the use of spatialRaster or spatialVector entities LTER has built applications based on spatial[Raster,Vector] entities Cons Data may not originate in ArcGIS, requiring a custom workflow to generate spatial entity EML Spatial[Raster,Vector] can?t describe multi-layer aggregates of GIS data (e.g., geodatabases containing multiple feature classes) Keywords Clearly identifying a dataset as spatial in nature is important to discoverability. This can be achieved by the use of keywords in the EML keyword elements as well as in the title/abstract and methods where appropriate. Keywords frequently searched include: GIS, geographic information system, spatial data, plus the more specific format names like shapefile, geoTIFF etc. Consider including as appropriate. Do include the keywords spatial vector and spatial raster as appropriate for your data. These keywords should be used especially if the data are archived as otherEntity. You may also include keywords that describe broad spatial data layers, e.g., digital elevation model, elevation, boundary, land use, land cover, census, parcel, imagery, as well as keywords that describe the specifics associated with a broad spatial data layer, e.g., land cover types such as water and vegetation types, land use types such as urban and forest, and so on. GIS software compatible metadata GIS platforms will not ingest EML metadata. If your GIS software creates its own metadata file specific to that software, then it may be included as otherEntity. Be sure to populate this metadata, for example with descriptions and units for attributes in vector data or raster attribute tables. However, metadata in the standard ISO 19115 or CSDGM format to enable the metadata to be read by other GIS software is more useful. Attribute and coordinate system detail for otherEntity While the GIS software compatible metadata included in the package typically describes attributes and coordinate systems of the data, such descriptions should also be included in the EML metadata to help users determine fit for use prior to data download. The EML spatialVector and spatialRaster types include elements for this purpose. EML otherEntity can also include attribute descriptions; however, inclusion of attributes in this more generic element may not be as common, and the element does not formally support a description of coordinate systems. When using otherEntity instead of spatialVector or spatialRaster, include coordinate system details in the otherEntity/entityDescription element. If not including a description of attributes in the otherEntity/attributeList element, at least include a summary description of attributes in otherEntity/entityDescription. If the spatial dataset and its associated metadata files are the only items in the data package, then you can include these descriptions in higher level EML elements such as the dataset abstract in addition to or in place of descriptions at the entity level. Standardized content for formats and entity types In EML physical/dataFormat/externallyDefinedFormat, include a formatName indicating the spatial data file format. We recommend using format names from the DataONE format list when possible. Some spatial items from that list are shown below. Always check the list for the most up-to-date version of these names. Esri Shapefile (zipped) Google Earth Keyhole Markup Language (KML) Google Earth Keyhole Markup Language (KML) Compressed archive Network Common Data Format, version 4 Hierarchical Data Format version 5 (HDF5) GeoTIFF GeoPackage Encoding Standard (OGC) Format Family Esri File Geodatabase (zipped) GeoJSON, version RFC 7946 If your format is not included in the DataONE list, consider submitting an issue to that GitHub repository’s issue tracker so that the format can be added. EML formatVersion, a sibling of formatName can be used to indicate the format version as in the example EML snippet below. &lt;externallyDefinedFormat&gt; &lt;formatName&gt;Network Common Data Format, version 4&lt;/formatName&gt; &lt;formatVersion&gt;netCDF-4 classic&lt;/formatVersion&gt; &lt;/externallyDefinedFormat&gt; For otherEntity, when populating the entityType element, use spatial raster or spatial vector as appropriate. "],["data-gathered-with-small-moving-platforms.html", "Data Gathered with Small Moving Platforms", " Data Gathered with Small Moving Platforms Contributors: Sarah Elmendorf (lead), Tim Whiteaker, Lindsay Barbieri, Jane Wyngaard, Greg Maurer, Hap Garritt, Adam Sapp, Corinna Gries, Stace Beaulieu Introduction Modern advances in technology have increasingly allowed the collection of ecological data using small, often uncrewed, moving platforms. Systems variously known as small Uncrewed Aircraft Systems (sUAS), Uncrewed Surface Vehicles (USV), Autonomous, Uncrewed Underwater Vehicles (AUV or UUV) or ?drones,? more generally, now frequently serve as sensor carrying platforms. Moving platforms may also include gliders or animals with sensors affixed. Depending on the sensor(s) installed on the moving platform, data collected may include environmental measurements (temperature, concentration of chemicals), imagery (digital photos, multi- or hyperspectral sensors), or other remote-sensing acquisitions (ranging data, ground-penetrating radar). Example research applications include studies of vegetation cover and phenology, snowpack cover and depth, ground surface temperature, terrain elevation, bathymetry, species distribution or abundance, and many others. Raw drone data can be voluminous and challenging to archive, but after processing, derived drone datasets typically resemble the more conventional spatial datasets that are regularly used in ecological research. In this document we focus on best practices for archiving raw and derived drone data, with particular attention to metadata and processing code that is specific to drone datasets. Note that this chapter does not specifically address data collected by large moving platforms like airplanes and satellites, or by human and animal platforms. Recommendations for data packages General considerations for archiving data from moving sensor platforms Repository: We are currently unaware of many specialized repositories for these data, and therefore, EDI is used as the representative data repository for many cases presented here. Repositories other than EDI may have specific metadata formatting requirements, but the general recommendations with regard to content could presumably be applied. For LiDAR based UAV data, consider contributing to Open Topography https://opentopography.org/); for AUV data, the U.S. Marine Geoscience Data System (MGDS) (http://www.marine-geo.org/index.php) which serves the IEDA “MGDL” node in DataONE is a good option. Glider data may be contributed to the U.S. IOOS Glider DAC (https://gliders.ioos.us/data/), archived at the National Centers for Environmental Information (NCEI) thus fulfilling NSF OCE Data Policy. If a decision is made to archive an LTER drone dataset in an external (i.e. non-EDI) repository but links to EDI data packages are desired, recommendations in the Data in Other Repositories chapter may apply. Size of data set: The file size of raw data from drone imagery can be substantial. If large volumes of raw data (&gt;100 GB in total) are to be archived on EDI, please coordinate with EDI and follow the best practices for Large Data Sets. Even if raw data are in a proprietary binary format and specific software is required for processing, publishing them may be important for reprocessing when software improves. Designing a data package: In many applications of moving sensor data, raw images/measurements must be processed to arrive at data products that can be analyzed to answer research questions. To enable a fully reproducible analysis pipeline, we recommend archiving three components: the raw data, any key derived data products (e.g., orthomosaic images, DEMs, DSMs, NDVI, landcover, snow depth, or surface temperature maps), and the processing code. These three components may be archived in separate data packages or together, and each should follow accepted best practices for its data type. To archive raw image collections, for example, see the considerations on grouping images into compressed archives (.zip, .tar) and creating an inventory file, as described in the Images and Documents as Data chapter. For derived geospatial files, such as DEMs, refer to the Spatial Data chapter. Custom processing code should be archived with the data following recommendations in the Code in EDI chapter. If a standalone program is used to process data, reference the program in the methods metadata with adequate details to ensure reproducibility (name, version, date, configuration, etc.). Metadata for moving platform data packages at EDI The data package should include metadata elements that, at a minimum, (a) identify it as being collected by a moving platform, (b) deliver basic information about the data collection platform, instrument payload (camera, sensors), and procedure (flight information or similar), and (c) deliver necessary information about post-processing of the raw camera or sensor data, if any. Accordingly, these recommendations vary based on whether the data package contains raw or derived data. High level metadata pertaining to the entire data package are easily provided in the EML file (e.g. a geographic bounding box). Data packages from drones or other moving platforms commonly include numerous point measurements, images, or other granular data entities, either separately or inside a compressed archive file. Detailed metadata pertaining to these data entities may be included as additional files in the data package. Inventory tables, usually a simple CSV file, are one such additional metadata format. For example, an inventory table could be used to list individual data files in the data package (e.g., images from one drone flight) and provide metadata (e.g. point location) about each. In addition to inventory tables, files that enable or supplement common processing pipelines, such as flight or mission logs, may be included. A flight/mission log may be provided in a proprietary binary format, but because software for parsing these formats may become obsolete, we recommend archiving the log in the format most useful for contemporary analysis software, and extracting and appending the information to the inventory file where appropriate. Exif (Exchangeable image file format) metadata in images may also be programmatically extracted to supplement the inventory file. Clearly, there are many possible ways to combine raw data, derived data, and metadata files into a moving platform data package. No matter the combination, the critical metadata categories and the recommended contents below should be considered and included where possible. The decision on whether to provide the metadata in EML or at a more granular level, such as an inventory table, will depend on the given dataset. Methods: unique identifier for a given flight or mission; summary information from a flight log; weather conditions; accuracy of sensor and geographic location information; data processing method; ground sample distance; image overlap; flight height; whether UAS followed terrain elevation vs fixed-height flight; location of UAS launch (since some image metadata are derived from this); general description of software used and for what purpose; sensor calibration date and procedure; general description of payload type, such as multispectral camera and spectral bands. Instrumentation: make and model of platform, sensor, and camera, including manufacturer and specific model names and numbers. Include make and model of any interchangeable lenses in cameras. Specifics like spectral bands, temperature range, sensor accuracy, etc. Software: (see also Code in EDI chapter) list of software used. Especially when code is proprietary or archived elsewhere, the name, version, and configuration of any software used are advisable, as are corrections applied (e.g., correction for sensor angle or heat/air flow). Ideally, a .pdf report generated by processing software can be archived as an otherEntity together with the imagery itself to convey much of the necessary information. Also include data used as a ground truth or calibration points for post processing (e.g. spectral calibration image/biomass sample/wind speed/etc) and their date of collection. People with specified role: drone operator, image processor Geographic Information: (see also Spatial Data chapter) a general bounding box should be included in EML, while the individual location of images or point measurements should be handled in the inventory table, or directly in the included data files. Also include the coordinate reference system (e.g., WGS 84) used for images and (if different) ground control points, projection type if needed, altitude of image/measurement acquisition, spatio-temporal coordinates, pitch, roll, and yaw from flight log or image data points. It should be noted that there are special considerations for underwater vehicles, especially with regard to metadata to explain how geographic positions were obtained. With autonomous underwater vehicles (AUVs), there can be error sources in the topside GPS localization, the underwater acoustic positioning system (e.g., Long Baseline, Ultrashort Baseline), as well as any sensors used for dead reckoning (e.g., accelerometer, Doppler Velocity Log). At a minimum, it would be useful to know which sensors were used to produce the localization data and whether the navigation tracklines were post-processed with benchmarks. Temporal Information: may also be provided at the EML level or as timestamps for individual data/image points, either in inventory tables or in the data files themselves. Time of day critically affects useability for image-based datasets; so ensure that the time of day is clear from the metadata available prior to download, either in the EML temporal coverage or via the methods. Keywords: Use of appropriate keywords aids in data discovery. Keywords that identify datasets as drone-related are therefore recommended (e.g. drone, UAV, UAS). Keywords describing the type of data collected are also recommended (e.g. image collection, aerial imagery, thermal imagery, NDVI, digital elevation map). For drone mapping data products, keyword recommendations from the Spatial Data chapter are largely applicable. Examples and additional metadata guidance Several EDI data packages for data from moving platforms are presented as examples in Table 1. Many more detailed, ?drone-specific? metadata terms and values can be included in data packages for drones and other moving platforms. For completeness we have developed a comprehensive list of recommended and optional metadata terms based on the work of Wyngaard et al. (2019), Thorner et al. (2020), with mappings to select relevant ontologies, viewable here. For each metadata element, we assessed its utility in terms of data discovery, evaluating fitness for use, and actual data reuse. The minimum recommended subsets of metadata that are included in the section above were derived from this table. Table 1. Example packages at EDI and other repositories Title Description EDI packageID Orthophoto and elevation models from UAV overflights at the G-IBPE study site at Jornada Basin LTER in 2019 Approximately 599 RGB images and data derived from uncrewed aerial vehicle (UAV) overflights of the G-IBPE study site at the Jornada Basin LTER in southern New Mexico, USA. knb-lter-jrn.210543001 Aerial imagery from unmanned aerial systems (UAS) flights and ground control points: Plum Island Estuary and Parker River NWR (PRNWR), February 27th, 2018. USGS Aerial imagery UAS flights at the Parker River National Wildlife Refuge, Massachusetts, USA, includes ground control, multispectral and true color child items which each have data entities that include ground control or a file catalog of images ScienceBase Spatial variability in water chemistry of four Wisconsin aquatic ecosystems - High speed limnology Environmental Science and Technology datasets water chemistry sensors embedded in a high-speed water intake system to document spatial variability. knb-lter-ntl.337.4 Thermal infrared, multispectral, and photogrammetric data collected by drone for hydrogeologic analysis of the East River beaver-impacted corridor near Crested Butte, Colorado infrared, multispectral, visual image data, and derivative products (orthomosaic and digital surface model) collected along a beaver-impacted section of the East River from August 12-17, 2017 and July 28-August 2, 2018. ScienceBase Resources Tips and Tricks For making an image catalog (.csv) from a directory of images, consider using the exif tool https://exiftool.org/. For example, the command ?exiftool.exe -csv -r mydirectory &gt; image_catalog.csv? will extract the entirety of the exif tags from all files stored under mydirectory into a comma-delimited table and write it to the the file image_catalog.csv Semantic Annotation Semantic annotation of drone imagery is a rapidly developing field. Ontologies that provide relevant terms include: dronetology; sensorML; FGDC content standard for digital geospatial metadata (not officially an ontology but a structured metadata format with defined terms); Semantic Sensor Network ontology (SSN, including the SOSA core); Semantic Web for Earth and Environment Technology ontology (SWEET); and Environment Ontology. References Thomer, Andrea K., Swanz, Sarah, Barbieri, Lindsay, Wyngaard, Jane. (2020). A minimum information framework the FAIR collection of earth and environmental science data with drones. DOI: 10.5281/zenodo.4017647 Wyngaard, J.; Barbieri, L.; Thomer, A.; Adams, J.; Sullivan, D.; Crosby, C.; Parr, C.; Klump, J.; Raj Shrestha, S.; Bell, T. Emergent Challenges for Science sUAS Data Management: Fairness through Community Engagement and Best Practices Development. Remote Sens. 2019, 11, 1797. "],["data-in-other-repositories.html", "Data in Other Repositories", " Data in Other Repositories Contributors: Greg Maurer (lead), Stace Beaulieu, RenÃ©e Brown, Sarah Elmendorf, Hap Garritt, Gastil Gastil-Buhl, Corinna Gries, Li Kui, An Nguyen, John Porter, Margaret O’Brien, Tim Whiteaker Introduction A wide variety of data repositories are available for publishing biological, environmental, and Earth observation data, and the choice of where to publish a particular dataset is determined by many competing factors. For example, a funding agency or journal may require a certain repository (e.g., NSF BCO-DMO, NSF ADC, USDA ADC, DOE ESS-DIVE); the research subject or data type may be best served by a specialized repository (e.g., AmeriFlux, GenBank); or datasets may be submitted to a general purpose repository with minimal metadata requirements to simplify and speed data publishing (e.g., DRYAD, Figshare, Zenodo). For these and other reasons related datasets are sometimes published in disparate data repositories, the same data needs to be discoverable in more than one repository, or multiple datasets from one or more repositories may be used to create a new, derived dataset. In such cases, it can be advantageous to establish links between datasets in different repositories such that provenance, supplementation, duplication or other relationships are explicit. Clearly, this subject goes well beyond the single repository and better standards and approaches for linking resources and documenting data provenance are being developed elsewhere (e.g. DataONE, ProvONE, WholeTale). Here we concentrate on specific cases in the context of large and multidisciplinary projects, such as LTER sites, that wish to enhance data discovery and preserve data relationships across multiple repositories. Recommendations for data packages Considerations for creating linked data In practice, links to data in other repositories can be achieved using metadata only, by including a data inventory file, or, although not recommended, by duplicating the data in the new repository record. Generally, duplicating data in multiple repositories is not recommended because it creates two problems. First, it is a burden to maintain multiple copies of a dataset and avoid divergence between them. Second, it can create confusion for data re-users who may download or cite the same data multiple times. Care must be taken to clearly identify such duplications for data users when they are created. Whenever linked datasets are created, it is strongly recommended that both repositories are aligned with FAIR data principles, outlined here, so that users have unfettered access to all data and metadata. In addition to these considerations, there are a number of reasons to create a new repository record that is linked to data in other repositories. Each of these reasons, which are outlined below, has pros and cons that will need to be weighed from the different perspectives of the data user, data provider and research project management requirements. Requirements dictate multiple repositories: Large research projects or sites are frequently funded by different agencies and programs. Data collection may be supported by several such funding streams and, hence, fall in the purview of more than one requirement to archive data in a particular repository. In some cases, data repositories already accommodate such requirements by linking or replicating data appropriately. Examples of this are LTER data in EDI, NSF BCO-DMO and NSF ADC. Adding important metadata: If data were originally submitted to a general purpose repository with minimal metadata requirements (e.g., DRYAD, figshare) additional metadata (e.g., EML) may be needed for discoverability, reusability, and integration. By creating a new repository record that identifies and is linked to the original published dataset, richer and more useful metadata can be added to the new record and utilized. Use of specialist repositories for related data: There are sometimes advantages to publishing particular data types in specialized repositories. Specialized data repositories (e.g. GenBank, AmeriFlux) usually enforce strict data formatting, provide quality standards, enhanced search, discovery and reuse of particular types of data across projects in a way that is not possible using a generalized metadata format (EML) and repository (EDI). However, these data may not be discoverable with other, related project data taken at the same location and time. Creating links between related datasets held in specialist and generalist repositories helps preserve this context. A derived data product is archived in a different repository than the source (raw) data: A wide range of cases fall into this category, from a direct one to one relationship of, e.g., a gene sequence and its OTU identification, a metagenome analysis and its community diversity metrics, to several datasets being combined in synthesis or meta-analysis studies. In these cases, links between source data and derived data products that are published in separate repositories need to be created and clearly documented. Linking to site- or project-relevant data from other research groups or agencies: Although it may help with some aspects of data discovery it is generally not recommended to create records in EDI for data collected and managed by entirely different research groups or agencies. In these cases, however, it is recommended to place a pointer to such repositories on a project website or develop other means for data users to discover relevant resources. General metadata for linked data packages in EDI In EDI, the linked data package can be assembled using standard practices and EML metadata elements, but the included metadata and data entities must clearly lead the data user to files held in outside repositories. In addition, the package metadata should communicate the essential elements needed for data discovery (subject matter, authors, location, time-frame, etc.) and a brief description of how the data may be accessed, re-used, and cited via the outside repository as needed. General guidance on the content and structure of key metadata elements in an EDI data package linked to data in other repositories are described below. Abstract: Describe the key features of the data package. If the data package contains only links to data held in other repositories, or data duplicated from another repository, clearly state that the original data are located in a different repository and direct the user to the correct data citation. Describe the target data in sufficient detail that users can determine whether these data are fit for their use, and instruct them on how to find and re-use the data. Methods: Collection/generation methods for any data entities included or linked to. If the methods are well-described in the metadata at another repository, this element can simply refer users there. If the new data package includes ancillary data or derived data, describe how those data were collected or derived. Geographic description and coordinates: At a minimum these elements should define a bounding box that will make the data package discoverable through EDI, DataOne, or other geographic search interfaces. Additional, more detailed coordinates may be given in the inventory file entity as described below. Keywords: Since some linked data packages include an inventory of data held at a different repository, include the keyword “data inventory” and thematic keywords that describe the data entities in the other repository. Common use cases and their structure in EDI There are several common use cases for creating a new linked data package in EDI. The new package may establish either a one-to-one link from EDI to a dataset in another repository, or a one-to-many relationship that is more complex. Three possible cases are described below in terms of what entities to publish, where to publish them, metadata elements to be created in EML, and the contents of included data entities. There are likely to be other use cases for linking EDI data packages to other repositories. Case 1: One dataset needs to be discoverable in more than one data repository. The data remain the same, but the metadata in the new data package at EDI may be upgraded beyond what exists in the other repository. The metadata in EDI must clearly state, preferably in the abstract or another obvious location, that this data package is already published in another repository. Include the original unique identifier and instruct users to cite that original data, if appropriate. Include instructions on how to access and cite the original data if the original repository is lacking in such guidance. If data are duplicated (which is not recommended), metadata should include information on how versions in different repositories are kept synchronized. If such synchronization is not feasible, users should be warned to inspect both sources for the latest data.. In EML the &lt;additionalIdentifier&gt; field may be used to store the persistent identifier (DOI), or a link (URL) that refers to the data held in another repository to make the link machine readable. Where an external repository supplies both a URL and DOI, use the DOI as URLs may not be maintained through time. Case 2: A list of data records held in a specialized repository needs to be linked to ancillary or supporting data that are being published in EDI (for derived data see Case 3). This case applies when a collection of datasets, or similar scientific resources, is held in a specialized repository and closely related ancillary or supporting data and metadata needs to be archived in a more generalist data repository like EDI. For example, ancillary environmental data or laboratory analyses held in EDI could be linked to collections of sequence reads held in NCBI GenBank or museum voucher specimens archived with Darwin Core metadata. See complete examples in Table 5.3. The new EDI data package should include a ‘data inventory’ (or manifest of holdings) file as a data entity. This is most likely a simple tabular data file, such as a CSV, that lists and describes the repository records held in the specialized data repository and has its column attributes described in EML as a dataTable entity. The inventory table must have a row for each outside repository record (or some meaningful grouping of records, e.g., project in NCBI) being linked to, with columns that include persistent unique identifiers of the data in the other repository, and relevant descriptors of the data. The complete content of the inventory will be dictated by the structure of the other repository and the data entities and metadata held there. Suggested columns are presented in Table 5.1. The inventory table may also provide additional contextual information for each individual data resource in another repository. Table 5.2 presents examples of these contextual columns. They are, however, subject dependent and may vary for different projects. For more examples, see the discussion on sequencing and genomic data later in this document. Table 1: Suggested columns for identifying the external data in the data inventory table. Column Description External unique ID Unique identifier for the data resource in the other repository. E.g. Accession number External access URL A unique, persistent link to the data resource in the other repository. Title/description Title and/or brief description of the data resource Filename(s) Dataset or file name at the other repository Format File format of above Repository URL URL of the repository being linked to Table 2: Examples of additional contextual columns in the data inventory table. Column Description Latitude/Longitude Latitude and longitude in standard format for each data resource in the other repository. Location name Locally used name of collection site Treatment level Experimental treatment applied to the outside dataset Start/End datetime Starting/ending datetime of the data resource (NA for End if data collection is ongoing) Reference publication DOI of publication providing in-depth context for data Case 3: One or more datasets in other repositories are used to create derived data products that need to be archived in EDI. In this case the new dataset is directly or indirectly derived from the ‘source’ dataset(s) in other repositories. Such derived data may serve a wide range of research purposes, including use in cross-site synthesis, re-analysis, or meta-analysis studies. Provenance metadata should be used to describe the relationship between the source and derived datasets, which ensures reproducibility and preserves data lineage. In a new EDI data package that archives derived data, the provenance metadata should be inserted in the EML file utilizing &lt;dataSource&gt; elements. The &lt;dataSource&gt; elements should be nested within a &lt;methodStep&gt; element and will establish the links to any source datasets located in another repository. An example snippet of provenance EML is shown in Figure 1. Other cross-repository standards for provenance metadata are still being developed and are not widely adopted, e.g., ProvONE. The EDI portal interface provides automatic generation of provenance metadata EML snippets for datasets in EDI. The EMLassemblyline and MetaEgress (in connection with LTER-core-metabase) R packages for EML creation will also generate provenance metadata. Example 1: EML snippet with a data provenance methodStep: &lt;methodStep&gt; &lt;description&gt; &lt;para&gt;This methodStep contains data provenance information as specified in the LTER EML Best Practices. Each dataSource element here lists entity-specific information and links to source data used in the creation of this derivative data package.&lt;/para&gt; &lt;/description&gt; &lt;dataSource&gt; &lt;title&gt;Source dataset title&lt;/title&gt; &lt;creator&gt; &lt;individualName&gt; &lt;givenName&gt;first name&lt;/givenName&gt; &lt;surName&gt;last name&lt;/surName&gt; &lt;/individualName&gt; &lt;organizationName&gt;organization name&lt;/organizationName&gt; &lt;electronicMailAddress&gt;email@some.edu&lt;/electronicMailAddress&gt; &lt;/creator&gt; &lt;distribution&gt; &lt;online&gt; &lt;onlineDescription&gt;This is a link to an external online data resource (describe resource and repository location).&lt;/onlineDescription&gt; &lt;url function=&quot;information&quot;&gt;https://pasta.lternet.edu/package/metadata/eml/knb-lter-ntl/80/2&lt;/url&gt; &lt;/online&gt; &lt;/distribution&gt; &lt;contact&gt; &lt;positionName&gt;Information Manager&lt;/positionName&gt; &lt;organizationName&gt;organization name&lt;/organizationName&gt; &lt;electronicMailAddress&gt;infomgr@some.edu&lt;/electronicMailAddress&gt; &lt;/contact&gt; &lt;/dataSource&gt; &lt;/methodStep&gt; Nucleotide sequence and genomic data Nucleotide sequence data consists of the order and arrangement of DNA or RNA bases extracted from individual organisms or environmental samples. Similarly, genomic data refers to the complete genetic information (either DNA or RNA) of an organism, while metagenomic data refers to the study of genomes recovered from environmental samples. Sequencing, genomic and metagenomic datasets can be very large and complex, and researchers in these fields benefit from particular methods of data access, analysis, and collaboration. Therefore, these data have specialized requirements for data archiving. Archiving nucleotide sequence and genomic (or other ‘omics’) data are a common use case for creating linked datasets. Data that originate from nucleotide sequencing techniques are most often stored in specialized repositories such as National Center for Biotechnology Information (NCBI) GenBank and the European Nucleotide Archive. However, while sequences or assembled genomes constitute important raw data, ancillary and derived data products related to these raw data are frequently published in repositories specializing in ecological data. For example, data derived from sequence data, such as operational taxonomic units (OTUs) or functional assignments, and ancillary data that describe the environmental, biochemical, or experimental context of the sequencing data, are often included in scientific publications, and do not always fit within the scope of a specialized sequence or genome data repository. Recommendations for sequencing or genomic datasets Linking to genomics data is an example of Case 2 described above. Summaries or inventories of data records held in a repository like NCBI GenBank are linked to their derived products or additional measurements published in a more generalist repository such as EDI. In addition to the metadata typically included with any data package published by the site or research group, include metadata that is descriptive specifically of sequencing and genomics datasets. It is recommended to refer to the MixS templates for standard terminology, especially in the keyword section: Keywords that can help users discover the sequencing or genomic dataset include: General data type descriptions (‘nucleotide sequence,’ ‘genomics,’ ‘metagenomics’) Names of target genes or subfragments (‘16S rRNA,’ ‘18S rRNA,’ ‘nif,’ ‘amoA,’ ‘rpo,’ ‘ITS’) Names of the sequencing technique (‘Sanger,’ ‘pyrosequencing,’ ‘ABI-solid’) Names of the linked repository (‘SRA,’ ‘EMBL,’ ‘Ensembl’) Descriptors of included ancillary data (‘nitrogen,’ ‘soil,’ ‘drought’) Descriptors of derived data products (‘OTU,’ ‘functional annotation,’ ‘population’) Inventory tables are of central importance to datasets that index data resources in a sequencing or genomics repository. It is recommended that this inventory should have the columns described in Table 1. Note that the unique identifiers included will depend on the granularity of the links to the outside repository. For example, in NCBI, there are accession numbers and URLs for a project, samples within the project, and sequence datasets from a given sample. External unique ID and URL: For NCBI GenBank this would be the accession number for a collection. For most sequence and genomic datasets an access URL would include an accession number (e.g. https://www.ncbi.nlm.nih.gov/nuccore/AY741555). Referring to a range of accession numbers, may involve providing a search URL that will return the desired list, e.g. (https://www.ncbi.nlm.nih.gov/popset/?term=AY741555). The recommendation is to link to the widest level of sequence or genomic granularity that is useful to interpret data being archived in the new dataset. The following are suggestions for additional contextual columns in the inventory table. This information is generally associated with the data in the genomics repository and should only be duplicated if deemed useful for reuse, or if missing in the original data. Sequencing method: the name of the sequencing method used; e.g., Sanger, pyrosequencing, ABI-solid. This attribute is used in MIxS templates, where it is called seq_meth. Environment (biome, feature, or material) descriptors: These are descriptors of the environmental context and are standardized by the genomics community in the MixS templates and EnvO. Taxon description: If applicable, e.g., Binomial name, or taxonomic group Data packages of metadata and inventory tables will aid in discovering genomic data within an ecological data repository (EDI) and will aid in clarifying the context in which they were collected. Most use cases, however, employ this inventory table to link specific genetic data to derived data. Such products frequently are community or population metrics where species, OTUs or traits have been determined from the sequence data. Example data packages in EDI Each of the EDI data packages below are linked to data in outside repositories. Some contain data inventory tables (as dataTable entities) that link to the datasets held in outside repositories and are described in the EML metadata. The EML abstract and methods elements in each give detailed access and citation instructions. Table 3: Linked data packages at EDI that provide examples of the best practices in this document. Title Description EDI packageID Mass and energy fluxes from the US-Jo2 AmeriFlux eddy covariance tower in Tromble Weir experimental watershed at the Jornada Basin LTER site, 2010-ongoing This data package links to eddy covariance data from a Jornada Basin LTER tower. The data are held at the AmeriFlux data repository (https://ameriflux.lbl.gov) knb-lter-jrn.210338005 Catalog of GenBank sequence read archive (SRA) entries of 16S and 18S rRNA genes from bacterial and protistan planktonic communities along the Eastern Beaufort Sea coast, North Slope, Alaska, 2011-2013 Data inventory of runs, samples, and experiments held at GenBank. knb-lter-ble.10 Correlation of native and exotic species richness: a global meta-analysis finds no invasion paradox across scales This data package re-publishes data held in a package in Dryad. The metadata has been substantially enriched relative to the original dataset. edi.548.1 Vascular Flora of the Harvard Farm at Harvard Forest since 2014 This data package includes an inventory table with information on voucher specimens held in the Harvard Herbarium. knb-lter-hfr.236.3 Biological responses to landscape change in the McMurdo Dry Valleys, Antarctica This data package links to genomic data in NCBI, and includes additional data from biogeochemical analyses performed on each sample. knb-lter-mcm.262.1 Appendix: Tips and repository information This section aggregates information helpful at the time this document was written, particularly regarding nucleotide sequence and genomic data repositories in widespread use at this time. Given the rapid rate of change in the field, this info may fall out of date quickly. Sequence and genomic repository information It is generally preferable that sequencing and genomic data are archived in community repositories that are specialized for their data type, rather than in a generalist repository such as the Environmental Data Initiative (EDI). There are many such specialized repositories; a fairly comprehensive listing is provided by the journal Nucleic Acids Research (summarized on this page). Metadata standards and collaborative structures among these repositories are governed by the International Nucleotide Sequence Database Collaboration (INSDC, more guidance here).Often these repositories provide or are accessible to specialized tools for searching, accessing, and analyzing the data (e.g., BLAST, MG-RAST). Furthermore, some products derived from sequence or genomic data are best archived in another specialized repository (e.g., metagenome-assembled genomes, or MAGs). As a general rule, these specialized repositories assign unique identifiers to projects, samples, and/or single sequences (often referred to as accession numbers) that can be used to locate sequences or genomic data. Note that each repository may have its own mechanism for reverse linking to related data held in another repository (such as EDI), and these mechanisms are beyond the scope of this document. NCBI Databases - list of various databases with search capabilities. See also How to submit data to GenBank. NCBI Accession Number prefixes - Explanation of accession number prefix codes. DNA DataBank of Japan (DDBJ) - list of various databases with search capabilities. See also Submissions. European Nucleotide Archive (ENA) - list of various databases with search capabilities. See also Submit and update. Integrated Microbial Genomes &amp; Microbiomes (IMG/M) system from the Joint Genome Institute MG-RAST (technically an analysis pipeline not a primary repository, but replicates to primary repositories) Replicates to the European Bioinformatics Institute (EMBL-EBI), which in turn replicates to the NCBI Sequence Read Archive (such that data submitted on MG-RAST will automatically appear on all three). Barcode of Life DataSystems (BOLD) DNA barcoding is a taxonomic method that uses one or more standardized short genetic markers in an organism’s DNA to identify it as belonging to a particular species. Through this method unknown DNA samples are identified to registered species based on comparison to a reference library. The Centre for Biodiversity Genomics in Canada maintains the BOLD public data portal, a cloud-based data storage and analysis platform. Tips for locating metadata in sequence and genomic data repositories Where information for populating metadata in EML has not been supplied directly to the IM from the research group, metadata that investigators provided when submitting data may be found in the genomics repository. For data in NCBI, go to the NCBI website and search using the accession number. Or search by accession number in a specific NCBI Database, for example Genes PopSet (the PopSet database is a collection of related DNA sequences derived from population, phylogenetic, mutation and ecosystem studies that have been submitted to NCBI). For sequences submitted to the NCBI Sequence Read Archive, there are some easily accessible online tools for generating tables of linked sequence data and their metadata. For an example, go to the example dataset at https://www.ncbi.nlm.nih.gbov/bioproject/305753, and click the number next to SRA Experiments to see a list of all experiments. Then click Send results to Run selector to see a table summarizing geolocations and associated metadata which could be archived at EDI or used to extract metadata for EML preparation. A full Data Carpentry tutorial on accessing data on the NCBI SRA database can be found here: Examining Data on the NCBI SRA Database BCO-DMO examples for contributing sequence accession numbers. Darwin Core standard for sequence data For sequence data to conform with the Darwin Core standard, a column header ‘associatedSequences’ (https://dwc.tdwg.org/terms/#dwc:associatedSequences) may be used in the inventory table populated with a unique identifier (or list of identifiers) for the sequence data (e.g., SNLBE002-17, a sequence in Barcode Of Life Data system, aka BOLD) or full URL (e.g., http://www.boldsystems.org/index.php/Public_RecordView?processid=SNLBE002-17). "],["large-data-sets.html", "Large Data Sets", " Large Data Sets Contributors: Margaret O’Brien, Corinna Gries, Mark Servilla Introduction Data entities are kept offline when they are too large to be handled easily by the HTTP protocol, are expected to be rarely requested, and can be mailed on an external drive. If you suspect your data fall into this category, contact EDI for advice (support@environmentaldatainitiative.org). Below are recommendations for the EDI repository’s handling of data packages that have an offline component. Background Standard practice is to handle data entities (both upload and download) via the HTTP protocol, using a URL. However, for very large datasets HTTP can fail due to physical limits. The limit for “too large” is somewhat subjective; EDI’s current limit for datasets that are “too large for HTTP” is 100GB (all data and metadata). Recommendations for data packages Physical Storage The use of a Solid-state Drive (SSD) is strongly recommended for all offline data storage. The SSD should be formatted using one of the following file systems: 1) exFAT, 2) NTFS, or 3) ext4. Each of these file systems can accommodate individual file sizes greater than 1TB. Add data to external drive in native (non-compressed, non-tarred, non-zipped) format, deliver to EDI (e.g., by physical mail). EDI will store three copies, one external hard drive each in New Mexico and in Wisconsin, one copy in general EDI backup cloud storage. Please mail one copy each to: Attn: Mark Servilla UNM Biology, Castetter Hall 1480 MSC03-2020, 219 Yale Blvd NE Albuquerque, NM 87131-0001 Attn: Corinna Gries University of Wisconsin Center for Limnology 680 North Park Street Madison WI 53706-1413 Access To receive offline data, send a request to support@environmentaldatainitiative.org listing the data package(s) of interest and we’ll determine the best mode of delivery. If technically feasible, we will stage data on an internet accessible host and will send you a URL when the data are ready for download. Otherwise, data will be sent on physical media. To receive data on physical media, you will be required to send a storage device of adequate volume to: Attn: Mark Servilla UNM Biology, Castetter Hall 1480 MSC03-2020 219 Yale Blvd NE Albuquerque, NM 87131-0001 We will utilize a delivery service of your choice, however, you will be responsible for all shipping arrangements and fees, including pre-arranging return delivery. Data package The external hard drive should contain at least two entities: the data (which will be offline) and an inventory or manifest that describe the contents of the external hard drive. Content of the manifest (inventory of holdings) would be dictated by the type of data entity. The manifest will be available as an online entity (through the EDI Data Portal) so that potential requestors can evaluate the offline resource before requesting it. Suggested columns are: Filename(s) Format (netCDF, tabular csv, etc.) Start_datetime End_datetime Location_lat Location_lon (other params the PIs may feel are essential) Checksum Package Metadata (in EDI metadata template and converted to EML - generally, as for any data package) Abstract: describe the collection generally. If individual files require specific software to read, provide the name of that software. Creators Contact - The first listed contact is responsible for sending out copies as requested and is typically the EDI repository manager: &lt;contact&gt; &lt;organizationName&gt;Environmental Data Initiative&lt;/organizationName&gt; &lt;electronicMailAddress&gt;support@environmentaldatainitiative.org&lt;/electronicMailAddress&gt; &lt;/contact&gt; Methods - detailed collection/generation methods for the offline data entities. Detailed information for re-using the data. (May instead be included in the manifest table if different for different offline files.) Data Entities Offline Entity: Describe as you would for an online resource. Restate the software needed to read the individual files if this is important to a user. See Table 1 and Sample XML. Manifest (inventory of the offline holdings) Column descriptions as for any data table EML In addition to basic resource-level metadata, at least two entities should be described: Manifest (inventory) should be a tableEntity: will be the online entity and described as all Offline entity: Fill out high-level fields as for an online resource. Restate the software needed to read the individual files if this is important to a user. Distribution node will be offline (See Table 1, code block) Table 1. Three required fields for an offline distribution physical/objectName As for any entity, this is the name of the file or data object dataFormat/ExternallyDefinedFormat/formatName The name of the format the data object is in. If there is a special compression applied, list it here. distribution/offline/mediumName Instead of a data URL, you will have an offline distribution node. The name of almost all offline media is “external drive,” because that is how you will deliver the data to a requestor. Sample XML, offline entity &lt;physical&gt; &lt;objectName&gt;mainl_2005acc.zip&lt;/objectName&gt; &lt;dataFormat&gt; &lt;externallyDefinedFormat&gt; &lt;formatName&gt;netCDF file&lt;/formatName&gt; &lt;/externallyDefinedFormat&gt; &lt;/dataFormat&gt; &lt;distribution&gt; &lt;offline&gt; &lt;mediumName&gt;External drive&lt;/mediumName&gt; &lt;/offline&gt; &lt;/distribution&gt; &lt;/physical&gt; References EML documentation https://eml.ecoinformatics.org/schema/index.html Look for the PhysicalDistributionType Potential Issues SSD formatting (eventually, whatever we use, it will become unusable). Even with cloud storage, eventually a binary format will become unusable. "],["scientific-domain.html", "Scientific Domain", " Scientific Domain This document contains current recommendations for data packages from specific scientific domains. Not all domains are covered. See navigation menu. "],["ecological-community-surveys.html", "Ecological community surveys", " Ecological community surveys DRAFT DRAFT DRAFT Introduction We know from experience that primary research data sets cannot be easily reused until all data are completely understood. Community survey data in particular, can be highly complex, often with location-specific methods. Some general principles can be summarized from: synthesis scientists working with this type of data lessons learned from harmonization of primary data, e.g., EDI’s ecocomDP project. Authors Margaret O’Brien (https://orcid.org/0000-0002-1693-8322) ecocomDP working group: https://environmentaldatainitiative.org/dataset-design/data-package-design-for-community-survey-data/ Anticipated use cases Synthesis Synthesis requires that primary research data sets be understood and combined into a similar format. EDI has examined the needs of synthesis scientists using community survey data, and that feedback is incorporated here. Harmonization Although a prescribed format would make data easily reused, the complexity of community surveys generally means that a prescribed format cannot be imposed on research studies. Therefore, EDI is harmonizing this data type in a workflow framework, and the lessons learned from examining raw data are included here. For more information on EDI’s harmonization of community survey data, see: - https://github.com/EDIorg/ecocomDP - https://environmentaldatainitiative.org/dataset-design/data-package-design-for-community-survey-data/ External applications Community survey data are of great interest to the broader biodiversity community, particularly through their support for portals such as GBIF, and the use of the Darwin Core Vocabulary. Harmonization is the first step in this process. Definitions and conventions The recommendations and examples below are organized according to how easily the data are reused. In all cases Best is preferred, and recommended. Marginal and not useable may overlap in some situations. - Best: Data are easily understood (do not require manual handling or further investigation) - OK: Some manual, custom or specialized handling required - Marginal: Additional metadata is required, along with custom handling and probably investigation (e.g., questions answered via email) - Not useable: the dataset has significant metadata missing; or has too many inconsistencies or layout challenges for it to be used even with manual handling. Recommendations for datasets Sampling methods Methods are generally text metadata * Best * explanation of the sampling strategy. * diagrams of sampling plots and their spatial relationships * OK * reference included to a paper describing the above * Marginal/not usable * no description of methods Dates Temporal sampling regime is consistent Best: A column for dateTime is in the entity, and its format is consistent throughout example: https://portal.edirepository.org/nis/metadataviewer?packageid=knb-lter-mcr.6.56 OK: sampling regime changes over time (yyyy, vs yyyy-mm-dd) * YYYY, vs YYYY-MM-DD Not useable: date and time columns are not typed in EML as dateTimes (i.e, typed as strings, as below) Synthesis efforts may be able to circumvent the lack of true dates by dropping records (and elevate a “not useable” dataset to “marginal”) *the ECC currently checks attributes typed as dateTime in two ways: format compared to a preferred list formats if the format is in the preferred list, checks agreement of data values with that format Locations Should be complete, with latitude and longitude Best: Columns for digital lat/lon example: https://portal.edirepository.org/nis/metadataviewer?packageid=edi.5.3 OK (need custom processing): In metadata only: example: https://portal.edirepository.org/nis/metadataviewer?packageid=knb-lter-sbc.17.33 Deg-min-sec (strings) Locations in second table Not useable: sites codes without lat/lon Site nesting Sampling site nesting can be understood Best: subsites are labeled example: https://portal.edirepository.org/nis/metadataviewer?packageid=edi.5.3 OK: Not useable: Taxa Taxa can be resolved Best: Taxon codes in the entity itself, assigned at source by those familiar with these taxonomic groups example: https://portal.edirepository.org/nis/metadataviewer?packageid=edi.3.5 OK: species binomials (ids will have to be added later, by someone less familiar with these taxa) example: https://portal.edirepository.org/nis/metadataviewer?packageid=knb-lter-sbc.17.33 Not useable: local codes only example (*if all they had included was the column called “sp_code”): https://portal.edirepository.org/nis/metadataviewer?packageid=knb-lter-sbc.17.33 Table column names Metadata can be matched to entity column Best: attributeName exactly matches column header example https://portal.edirepository.org/nis/metadataviewer?packageid=edi.3.5 OK: can be matched by manual examination example https://portal.edirepository.org/nis/metadataviewer?packageid=knb-lter-mcr.1039.9 Marginal: no header example This feature has come up in other discussions. The EML metadata asserts what the content of a column is, however there is no explicit “key” into that column except for the column header in the data entity itself. If these do not match (or there is no table header), then there is nothing to go on but trust. That’s fine if data are shared only within a tightly knit community, but is less reliable when data are reused outside the orginating group. the ECC currently checks that number of columns and their typing match (within the limits of an RDB). For attributeNames, It shows you the first line of the table for manual comparison (an info check). Table linkages Foreign Key linkages are clear Best: EML constraint included, with referential integrity example https://portal.edirepository.org/nis/metadataviewer?packageid=knb-lter-mcr.6.56 OK: FK detected manually, has referential integrity url Not useable: FK detected manually, but no referential integrity url Table linkages are most important for harmonization; synthesis efforts may be able to circumvent issues (and elevate a “not useable” dataset to “marginal”) by dropping records without referents in key fields. "],["meteorology-and-hydrology-data.html", "Meteorology and Hydrology data", " Meteorology and Hydrology data Introduction This is a summary page. it should have links out for details. Synthesis use para here about CUAHSI, with link to that project. Recommendations for datasets summary here. "],["soil-carbon.html", "Soil Carbon", " Soil Carbon Introduction Page desribing BPs for data packages about soil carbon. it will probably have links out for details. Synthesis use para here about current synthesis use, eg, Weider WG. Recommendations for datasets summary here. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
